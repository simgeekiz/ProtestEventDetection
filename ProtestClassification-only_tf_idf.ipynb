{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data/20181001-newindianexpress_sentence_classification_adjudicated_20181218.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.logical_not(np.isnan(np.array(df['label'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_stopwords = [str(i) for i in range(10001)] + ['0'+str(i) for i in range(100)] + ['000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'f1_macro'\n",
    "n_jobs=20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that best TFIDFVectorizer features are as listed below;\n",
    "    min_df: 0.0001\n",
    "    max_df: 0.6\n",
    "    stop_words: num_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.0001, max_df=0.6, stop_words=number_stopwords)\n",
    "tfidf_vectors = vectorizer.fit_transform(df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = 'Data/features_mindf_0001_maxdf_6_number_stopwords.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(feature_path, 'wb') as file_:\n",
    "    pickle.dump(tfidf_vectors, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(feature_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_vectors\n",
    "del df\n",
    "del nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "- With hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = {}\n",
    "opt_results_path = 'Results/optimization_results_tfidf_only.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Note on the Scoring of Parameter Optimization\n",
    "GridSearchCV uses mean accuracy by default. However, we have chosen \"f1_macro\" scoring for hyper-parameter optimization, because mean accuracy or f1_micro is measuring the performance on the total labels, disregarding the type of the label. So, when we use accuracy or f1_micro, we get high scores because most of the labels are 0 and classifier predicts most of the labels as 0. When the accuracy score for the label 0 is high, the overall result becomes high as well, eventhough the other labels perform low. And this kind of high score doesn't mean our classifier performs better because we are actually interested in getting high scores on label 1 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "        ('feat_sel', SelectPercentile(score_func=chi2)),\n",
    "        ('clf', DecisionTreeClassifier(criterion='gini'))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "params = {\n",
    "    'feat_sel__percentile': (10, 90, 100),\n",
    "    'clf__max_depth': [None] + [*range(15, 35, 5)],\n",
    "    'clf__min_samples_split': [*range(50, 200, 40)],\n",
    "    'clf__min_samples_leaf': [*range(5, 14, 2)],\n",
    "    'clf__max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dt_clf = GridSearchCV(classifier, params, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "dt_clf = dt_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feat_sel', SelectPercentile(percentile=100, score_func=<function chi2 at 0x2b651a28b488>)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=50,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "Best Score\n",
      "0.5189803679237573\n",
      "Best Params\n",
      "{'clf__max_features': None, 'clf__max_depth': None, 'clf__min_samples_leaf': 5, 'feat_sel__percentile': 100, 'clf__min_samples_split': 50}\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator')\n",
    "print(dt_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(dt_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(dt_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, cross_val_predict(dt_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['DecisionTree'] = {}\n",
    "opt_results['DecisionTree']['GridSearchCV'] = dt_clf\n",
    "opt_results['DecisionTree']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91      6876\n",
      "         1.0       0.53      0.45      0.48      1299\n",
      "         2.0       0.36      0.10      0.16       162\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      8337\n",
      "   macro avg       0.59      0.50      0.52      8337\n",
      "weighted avg       0.83      0.84      0.83      8337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8481468154012235\n",
    "{'max_depth': 20, 'min_samples_split': 100, 'max_features': None, 'min_samples_leaf': 9}\n",
    "699\n",
    "<function _passthrough_scorer at 0x2ba712f58950>\n",
    "5\n",
    "0.30017995834350586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "        ('feat_sel', SelectPercentile(score_func=chi2)),\n",
    "        ('clf', RandomForestClassifier(criterion='gini'))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'feat_sel__percentile': (10, 90, 100),\n",
    "    'clf__n_estimators': [30, 70, 100, 150], \n",
    "    'clf__max_depth': [None] + [*range(65, 120, 15)], \n",
    "    'clf__min_samples_split': [25, 30, 40, 45, 50, 100],\n",
    "    'clf__max_features': ['sqrt', 'log2'],\n",
    "    'clf__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_clf = GridSearchCV(classifier, params, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "rf_clf = rf_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Estimator\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=40,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "Best Score\n",
    "0.860501379393067\n",
    "Best Params\n",
    "{'bootstrap': False, 'max_features': 'auto', 'max_depth': 80, 'n_estimators': 30, 'min_samples_split': 40, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feat_sel', SelectPercentile(percentile=10, score_func=<function chi2 at 0x2b651a28b488>)), ('clf', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_im...obs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n",
      "Best Score\n",
      "0.47254814698253395\n",
      "Best Params\n",
      "{'clf__max_features': 'sqrt', 'clf__bootstrap': False, 'feat_sel__percentile': 10, 'clf__max_depth': None, 'clf__min_samples_split': 45, 'clf__n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator')\n",
    "print(rf_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(rf_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(rf_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, cross_val_predict(rf_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['RandomForest'] = {}\n",
    "opt_results['RandomForest']['GridSearchCV'] = rf_clf\n",
    "opt_results['RandomForest']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93      6876\n",
      "         1.0       0.66      0.36      0.47      1299\n",
      "         2.0       0.25      0.01      0.01       162\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      8337\n",
      "   macro avg       0.60      0.45      0.47      8337\n",
      "weighted avg       0.83      0.86      0.84      8337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "        ('feat_sel', SelectPercentile(score_func=chi2)),\n",
    "        ('clf', SVC())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'feat_sel__percentile': (10, 90, 100),\n",
    "    'clf__kernel': ('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "    'clf__C': [0.025, 0.25, 0.5, 1, 2, 3],\n",
    "}\n",
    "          \n",
    "svc_clf = GridSearchCV(classifier, params, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "svc_clf = svc_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feat_sel', SelectPercentile(percentile=90, score_func=<function chi2 at 0x2b651a28b488>)), ('clf', SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))])\n",
      "Best Score\n",
      "0.5527827921091951\n",
      "Best Params\n",
      "{'clf__kernel': 'linear', 'clf__C': 3, 'feat_sel__percentile': 90}\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator')\n",
    "print(svc_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(svc_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(svc_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, cross_val_predict(svc_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['SVC'] = {}\n",
    "opt_results['SVC']['GridSearchCV'] = svc_clf\n",
    "opt_results['SVC']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92      6876\n",
      "         1.0       0.63      0.45      0.52      1299\n",
      "         2.0       0.75      0.13      0.22       162\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      8337\n",
      "   macro avg       0.76      0.51      0.56      8337\n",
      "weighted avg       0.85      0.86      0.85      8337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8642197433129423\n",
    "{'C': 2, 'gamma': 'auto', 'kernel': 'linear'} 'C':[0.025, 0.25, 0.5, 1, 2, 3, 5, 8, 10, 15, 20], \n",
    "48\n",
    "<function _passthrough_scorer at 0x2ba712f58950>\n",
    "5\n",
    "9.254388332366943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_knn = Pipeline([\n",
    "        ('feat_sel', SelectPercentile(score_func=chi2)),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "# p: Power parameter for the Minkowski metric. When p = 1, \n",
    "#    this is equivalent to using manhattan_distance (l1), \n",
    "#    and euclidean_distance (l2) for p = 2. \n",
    "#    For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "params = {\n",
    "    'feat_sel__percentile': (10, 90, 100),\n",
    "    'clf__n_neighbors': [3, 5, 9, 13, 19, 25, 35, 55, 63], \n",
    "    'clf__leaf_size': [20, 30, 40, 50, 60],\n",
    "    'clf__p': [1, 2, 3]\n",
    "}\n",
    "          \n",
    "knn_clf = GridSearchCV(classifier_knn, params, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "knn_clf = knn_clf.fit(X.todense(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator')\n",
    "print(knn_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(knn_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(knn_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, cross_val_predict(knn_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['KNeighbors'] = {}\n",
    "opt_results['KNeighbors']['GridSearchCV'] = knn_clf\n",
    "opt_results['KNeighbors']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(opt_results_path, 'rb') as file_:\n",
    "    opt_results = pickle.load(file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "   #     ('tfidf', TfidfVectorizer()),\n",
    "        ('feat_sel', SelectPercentile(score_func=chi2)),\n",
    "        ('clf', MLPClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  #  'tfidf__max_df':(0.999, 0.60),\n",
    "  #  'tfidf__min_df':(0.0009, 0.001, 0.003),\n",
    "  #  'tfidf__stop_words': ('english',None, number_stopwords),\n",
    "    'feat_sel__percentile': (10, 90, 100),\n",
    "    'clf__hidden_layer_sizes': [(10,5), (20,10), (20), (30,20), (50,30)], \n",
    "    'clf__activation': ['tanh', 'relu', 'logistic'], \n",
    "    'clf__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'clf__learning_rate_init': [0.01, 0.001, 0.1],\n",
    "    'clf__max_iter': [50, 200, 400]\n",
    "}\n",
    "                        \n",
    "mlp = MLPClassifier()\n",
    "mlp_clf = GridSearchCV(classifier, params, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "mlp_clf = mlp_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator')\n",
    "print(clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(clf.best_score_)\n",
    "print('Best Params')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, cross_val_predict(mlp_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results['MLP'] = {}\n",
    "opt_results['MLP']['GridSearchCV'] = mlp_clf\n",
    "opt_results['MLP']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ... add import for Kmeans"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'n_clusters': [3, 4, 5, 6, 7, 8, 10, 15, 25, 32],\n",
    "    'n_init': [*range(5, 25, 5)],\n",
    "    'max_iter': [*range(200, 450, 100)],\n",
    "    'precompute_distances': ('auto'),\n",
    "    'algorithm' : ('auto', 'full', 'elkan'),\n",
    "}\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans_clf = GridSearchCV(kmeans, params, cv=5, scoring=scoring)\n",
    "kmeans_clf = kmeans_clf.fit(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Best Estimator')\n",
    "print(kmeans_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(kmeans_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(kmeans_clf.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_true, y_pred = y, cross_val_predict(kmeans_clf.best_estimator_, X, y, n_jobs=n_jobs, cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "opt_results['KMeans'] = {}\n",
    "opt_results['KMeans']['GridSearchCV'] = kmeans_clf\n",
    "opt_results['KMeans']['classif_report'] = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(opt_results_path, 'wb') as file_:\n",
    "    pickle.dump(opt_results, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All classifiers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "names = ['Nearest Neighbors', 'Linear SVM', 'RBF SVM', 'Gaussian Process',\n",
    "         'Decision Tree', 'Random Forest', 'Neural Net', 'AdaBoost',\n",
    "         'Naive Bayes']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel='linear', C=0.025),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    SVC,\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(criterion='gini'),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result_file = open('scikit_learn_results.txt', 'w') \n",
    "for name, classifier in zip(names, classifiers):\n",
    "    print('Running: ', name)\n",
    "    y_true, y_pred = y, cross_val_predict(classifier, X, y, n_jobs=n_jobs, cv=3)\n",
    "    result_file.write('\\n\\n--- ' + name + ' ---')\n",
    "    result_file.write('\\nPrecision:' + str(precision_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nRecall:' + str(recall_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nF1-score:' + str(f1_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nAccuracy:' + str(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "result_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
