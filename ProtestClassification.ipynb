{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data/20181001-newindianexpress_sentence_classification_adjudicated_20181218.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.logical_not(np.isnan(np.array(df['label'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.002, max_df=0.95, stop_words='english')\n",
    "tfidf_vectors = vectorizer.fit_transform(df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8337x1320 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68153 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection on TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = SelectPercentile(chi2, percentile=80).fit_transform(tfidf_vectors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8337, 1056)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tagset = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT',\n",
    "              'WORK_OF_ART', 'LAW', 'LANGUAGE', 'DATE', 'TIME', 'PERCENT',\n",
    "              'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_entities(sentence, ner_tagset):\n",
    "    entities = [token.label_ for token in nlp(sentence).ents]\n",
    "    # frequency word count\n",
    "    bag = np.zeros(len(ner_tagset))\n",
    "    for ent in entities:\n",
    "        for i, entity in enumerate(ner_tagset):\n",
    "            if ent==entity:\n",
    "                bag[i] += 1\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_features = []\n",
    "for i,row in df.iterrows():\n",
    "    ner_features.append(bag_of_entities(row['sentence'], ner_tagset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining TF-IDF Vectors and Named Entity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack((tfidf_vectors, np.array(ner_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = 'Data/feature_list_optimized_Tf_idf_ner_features_sparse_matrix.pickle'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(feature_path, 'wb') as file_:\n",
    "    pickle.dump(X, file_, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.coo.coo_matrix"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tfidf_vectors\n",
    "del df\n",
    "del ner_features\n",
    "del nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "- With hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "params = {\n",
    "    'max_depth': [None] + [*range(15, 35, 5)],\n",
    "    'min_samples_split': [*range(50, 200, 40)],\n",
    "    'min_samples_leaf': [*range(5, 14, 2)],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt_clf = GridSearchCV(dt, params, cv=5)\n",
    "dt_clf = dt_clf.fit(X, y)\n",
    "\n",
    "opt_results['DecisionTree'] = dt_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=50,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Best Score\n",
      "0.8518651793210987\n",
      "Best Params\n",
      "{'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 15}\n",
      "cv_results_\n",
      "{'param_min_samples_split': masked_array(data=[50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170,\n",
      "                   50, 90, 130, 170, 50, 90, 130, 170, 50, 90, 130, 170],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': None}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 15}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 20}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 25}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': None, 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'sqrt', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 9, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 11, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 50, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 90, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 130, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 30}, {'min_samples_split': 170, 'min_samples_leaf': 13, 'max_features': 'log2', 'max_depth': 30}], 'split2_train_score': array([0.88785607, 0.87781109, 0.87331334, 0.86671664, 0.88215892,\n",
      "       0.87391304, 0.86896552, 0.86401799, 0.87766117, 0.87061469,\n",
      "       0.86581709, 0.86086957, 0.87181409, 0.86596702, 0.86071964,\n",
      "       0.85697151, 0.86581709, 0.85847076, 0.85637181, 0.85322339,\n",
      "       0.86521739, 0.86011994, 0.86101949, 0.85997001, 0.84602699,\n",
      "       0.85322339, 0.85262369, 0.84347826, 0.85172414, 0.85142429,\n",
      "       0.85592204, 0.85937031, 0.84737631, 0.85082459, 0.85607196,\n",
      "       0.83613193, 0.83838081, 0.84437781, 0.84587706, 0.84287856,\n",
      "       0.85427286, 0.84272864, 0.84962519, 0.84017991, 0.84017991,\n",
      "       0.83853073, 0.84032984, 0.83988006, 0.83598201, 0.83628186,\n",
      "       0.83493253, 0.83538231, 0.84017991, 0.83463268, 0.84497751,\n",
      "       0.83628186, 0.82983508, 0.83793103, 0.84317841, 0.82983508,\n",
      "       0.87571214, 0.86776612, 0.86311844, 0.85652174, 0.87271364,\n",
      "       0.86536732, 0.86026987, 0.85532234, 0.87061469, 0.86431784,\n",
      "       0.85952024, 0.85457271, 0.86791604, 0.86266867, 0.85742129,\n",
      "       0.85367316, 0.86461769, 0.85802099, 0.85592204, 0.85277361,\n",
      "       0.84737631, 0.84002999, 0.83793103, 0.84692654, 0.84497751,\n",
      "       0.84767616, 0.83838081, 0.83688156, 0.85322339, 0.84257871,\n",
      "       0.84227886, 0.83598201, 0.83343328, 0.83523238, 0.83778111,\n",
      "       0.84242879, 0.84482759, 0.83238381, 0.84542729, 0.83448276,\n",
      "       0.83733133, 0.83148426, 0.82938531, 0.82878561, 0.83433283,\n",
      "       0.82758621, 0.83193403, 0.82908546, 0.82818591, 0.83958021,\n",
      "       0.83163418, 0.82878561, 0.82878561, 0.82923538, 0.83178411,\n",
      "       0.82803598, 0.83163418, 0.82998501, 0.83238381, 0.83283358,\n",
      "       0.88035982, 0.87181409, 0.86716642, 0.86056972, 0.87676162,\n",
      "       0.86941529, 0.86431784, 0.85937031, 0.87406297, 0.86761619,\n",
      "       0.86281859, 0.85787106, 0.87016492, 0.86476762, 0.85952024,\n",
      "       0.85577211, 0.86506747, 0.85847076, 0.85622189, 0.85307346,\n",
      "       0.85442279, 0.84422789, 0.84932534, 0.84587706, 0.83328336,\n",
      "       0.84827586, 0.84827586, 0.85007496, 0.83673163, 0.83718141,\n",
      "       0.84062969, 0.83883058, 0.84317841, 0.84257871, 0.84617691,\n",
      "       0.83883058, 0.83403298, 0.83703148, 0.84047976, 0.84107946,\n",
      "       0.83523238, 0.83298351, 0.83373313, 0.83358321, 0.83193403,\n",
      "       0.83208396, 0.84152924, 0.83778111, 0.84137931, 0.83328336,\n",
      "       0.83673163, 0.83418291, 0.82908546, 0.84092954, 0.83928036,\n",
      "       0.82908546, 0.83028486, 0.83613193, 0.82848576, 0.83088456,\n",
      "       0.88425787, 0.87511244, 0.87046477, 0.86386807, 0.88035982,\n",
      "       0.87271364, 0.86761619, 0.86266867, 0.87571214, 0.86926537,\n",
      "       0.86446777, 0.85952024, 0.87136432, 0.86596702, 0.86071964,\n",
      "       0.85697151, 0.86491754, 0.85847076, 0.85637181, 0.85322339,\n",
      "       0.84722639, 0.84272864, 0.85322339, 0.85277361, 0.85922039,\n",
      "       0.85112444, 0.85322339, 0.84917541, 0.85412294, 0.83778111,\n",
      "       0.83853073, 0.84767616, 0.84317841, 0.85457271, 0.85127436,\n",
      "       0.84062969, 0.83568216, 0.83388306, 0.83703148, 0.84632684,\n",
      "       0.83763118, 0.83178411, 0.83283358, 0.84257871, 0.83373313,\n",
      "       0.83388306, 0.83703148, 0.83733133, 0.84842579, 0.83103448,\n",
      "       0.84257871, 0.83193403, 0.82848576, 0.83523238, 0.83478261,\n",
      "       0.84077961, 0.82773613, 0.83208396, 0.83538231, 0.83718141,\n",
      "       0.88545727, 0.87601199, 0.87136432, 0.86461769, 0.88095952,\n",
      "       0.87316342, 0.86806597, 0.86311844, 0.87661169, 0.87016492,\n",
      "       0.86536732, 0.86041979, 0.87136432, 0.86596702, 0.86071964,\n",
      "       0.85697151, 0.86581709, 0.85862069, 0.85637181, 0.85322339,\n",
      "       0.85052474, 0.85892054, 0.84752624, 0.85397301, 0.85352324,\n",
      "       0.84347826, 0.85802099, 0.85652174, 0.84497751, 0.84947526,\n",
      "       0.84362819, 0.85022489, 0.83793103, 0.84812594, 0.84497751,\n",
      "       0.84272864, 0.83388306, 0.83658171, 0.83493253, 0.83868066,\n",
      "       0.83988006, 0.83838081, 0.84317841, 0.84317841, 0.84047976,\n",
      "       0.83223388, 0.84107946, 0.84392804, 0.83373313, 0.83238381,\n",
      "       0.83838081, 0.83193403, 0.84437781, 0.83883058, 0.83763118,\n",
      "       0.84047976, 0.82833583, 0.83133433, 0.84482759, 0.83418291]), 'split1_test_score': array([0.84292566, 0.8411271 , 0.83872902, 0.83333333, 0.83693046,\n",
      "       0.83273381, 0.83393285, 0.82913669, 0.83393285, 0.83453237,\n",
      "       0.83513189, 0.82973621, 0.83992806, 0.84052758, 0.84232614,\n",
      "       0.83932854, 0.82913669, 0.83213429, 0.83513189, 0.83213429,\n",
      "       0.81354916, 0.82973621, 0.83093525, 0.82793765, 0.82853717,\n",
      "       0.82194245, 0.81294964, 0.82913669, 0.81414868, 0.82434053,\n",
      "       0.82314149, 0.82793765, 0.82434053, 0.84172662, 0.82494005,\n",
      "       0.81235012, 0.82673861, 0.83393285, 0.83273381, 0.82973621,\n",
      "       0.83153477, 0.81834532, 0.8147482 , 0.80815348, 0.81894484,\n",
      "       0.81834532, 0.82434053, 0.82134293, 0.81414868, 0.82074341,\n",
      "       0.8147482 , 0.81954436, 0.8147482 , 0.83513189, 0.83393285,\n",
      "       0.81834532, 0.82014388, 0.82074341, 0.82134293, 0.82973621,\n",
      "       0.85191847, 0.84952038, 0.8471223 , 0.84172662, 0.84892086,\n",
      "       0.84352518, 0.84592326, 0.8411271 , 0.84172662, 0.84232614,\n",
      "       0.84292566, 0.83752998, 0.84232614, 0.84292566, 0.84472422,\n",
      "       0.84172662, 0.83573141, 0.83872902, 0.84172662, 0.83872902,\n",
      "       0.84052758, 0.83213429, 0.82673861, 0.82374101, 0.82314149,\n",
      "       0.83393285, 0.83333333, 0.81834532, 0.82853717, 0.83093525,\n",
      "       0.82733813, 0.82374101, 0.81534772, 0.83872902, 0.83453237,\n",
      "       0.83033573, 0.82613909, 0.82494005, 0.82434053, 0.81294964,\n",
      "       0.83273381, 0.82074341, 0.83153477, 0.83513189, 0.82314149,\n",
      "       0.82913669, 0.83393285, 0.82494005, 0.81834532, 0.81894484,\n",
      "       0.82733813, 0.82374101, 0.81354916, 0.82673861, 0.82434053,\n",
      "       0.81834532, 0.82014388, 0.82793765, 0.82254197, 0.82134293,\n",
      "       0.85071942, 0.84952038, 0.8471223 , 0.84052758, 0.84592326,\n",
      "       0.84172662, 0.84292566, 0.8381295 , 0.83693046, 0.83752998,\n",
      "       0.8381295 , 0.83273381, 0.83992806, 0.84052758, 0.84232614,\n",
      "       0.83932854, 0.83033573, 0.83333333, 0.83633094, 0.83333333,\n",
      "       0.83213429, 0.83573141, 0.84952038, 0.82793765, 0.84292566,\n",
      "       0.82553957, 0.84292566, 0.83693046, 0.82973621, 0.83393285,\n",
      "       0.82014388, 0.81894484, 0.82793765, 0.82913669, 0.83573141,\n",
      "       0.82254197, 0.83393285, 0.84052758, 0.82553957, 0.82553957,\n",
      "       0.82853717, 0.83153477, 0.82613909, 0.81894484, 0.82074341,\n",
      "       0.83333333, 0.82434053, 0.83633094, 0.82134293, 0.82314149,\n",
      "       0.81714628, 0.82553957, 0.82074341, 0.81714628, 0.82434053,\n",
      "       0.83213429, 0.83872902, 0.83033573, 0.82553957, 0.82793765,\n",
      "       0.84832134, 0.84652278, 0.8441247 , 0.83752998, 0.84232614,\n",
      "       0.8381295 , 0.83932854, 0.83453237, 0.83393285, 0.83453237,\n",
      "       0.83513189, 0.82973621, 0.83992806, 0.84052758, 0.84232614,\n",
      "       0.83932854, 0.82913669, 0.83213429, 0.83513189, 0.83213429,\n",
      "       0.85311751, 0.83273381, 0.81594724, 0.83033573, 0.82613909,\n",
      "       0.83633094, 0.82254197, 0.82134293, 0.83153477, 0.82254197,\n",
      "       0.83453237, 0.82853717, 0.83273381, 0.83213429, 0.82733813,\n",
      "       0.82074341, 0.82613909, 0.82913669, 0.82853717, 0.82973621,\n",
      "       0.82314149, 0.82673861, 0.82733813, 0.82434053, 0.82254197,\n",
      "       0.82494005, 0.83033573, 0.83333333, 0.82014388, 0.82494005,\n",
      "       0.82853717, 0.82733813, 0.82314149, 0.81954436, 0.83633094,\n",
      "       0.83513189, 0.83992806, 0.82014388, 0.82673861, 0.83093525,\n",
      "       0.84772182, 0.8441247 , 0.84172662, 0.83752998, 0.84052758,\n",
      "       0.83573141, 0.83693046, 0.83273381, 0.83393285, 0.83453237,\n",
      "       0.83513189, 0.82973621, 0.83992806, 0.84052758, 0.84232614,\n",
      "       0.83932854, 0.82913669, 0.83213429, 0.83513189, 0.83213429,\n",
      "       0.82913669, 0.82973621, 0.83393285, 0.83872902, 0.82494005,\n",
      "       0.82374101, 0.82793765, 0.84052758, 0.84052758, 0.82553957,\n",
      "       0.82553957, 0.80935252, 0.82853717, 0.8411271 , 0.82733813,\n",
      "       0.82553957, 0.83273381, 0.81894484, 0.82254197, 0.83752998,\n",
      "       0.82254197, 0.82434053, 0.81894484, 0.81714628, 0.81894484,\n",
      "       0.84472422, 0.82973621, 0.81115108, 0.82673861, 0.82853717,\n",
      "       0.81834532, 0.81354916, 0.83633094, 0.81954436, 0.82134293,\n",
      "       0.82194245, 0.82973621, 0.83453237, 0.83513189, 0.82673861]), 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split3_train_score': array([0.88830585, 0.88065967, 0.87571214, 0.86956522, 0.88215892,\n",
      "       0.87616192, 0.87151424, 0.86536732, 0.87856072, 0.87331334,\n",
      "       0.87016492, 0.86401799, 0.87481259, 0.86851574, 0.86746627,\n",
      "       0.86296852, 0.86881559, 0.86401799, 0.86401799, 0.85907046,\n",
      "       0.86281859, 0.87046477, 0.86476762, 0.85802099, 0.85262369,\n",
      "       0.86041979, 0.85877061, 0.85832084, 0.85097451, 0.84527736,\n",
      "       0.85622189, 0.84782609, 0.85142429, 0.85367316, 0.84137931,\n",
      "       0.85277361, 0.84002999, 0.84512744, 0.83433283, 0.83973013,\n",
      "       0.85082459, 0.85052474, 0.84842579, 0.85127436, 0.84287856,\n",
      "       0.85217391, 0.84962519, 0.83943028, 0.83793103, 0.83703148,\n",
      "       0.83868066, 0.83223388, 0.83118441, 0.83568216, 0.83583208,\n",
      "       0.83298351, 0.84122939, 0.82998501, 0.84092954, 0.83733133,\n",
      "       0.87706147, 0.87061469, 0.86626687, 0.86011994, 0.87616192,\n",
      "       0.87031484, 0.86626687, 0.86011994, 0.87406297, 0.86941529,\n",
      "       0.86626687, 0.86011994, 0.87121439, 0.86551724, 0.86446777,\n",
      "       0.85997001, 0.86746627, 0.86326837, 0.86326837, 0.85832084,\n",
      "       0.85082459, 0.84227886, 0.84722639, 0.84737631, 0.84557721,\n",
      "       0.84272864, 0.84287856, 0.84212894, 0.84362819, 0.85412294,\n",
      "       0.84467766, 0.83538231, 0.84632684, 0.84002999, 0.83928036,\n",
      "       0.84737631, 0.84662669, 0.83103448, 0.84212894, 0.83508246,\n",
      "       0.83253373, 0.83553223, 0.82863568, 0.83178411, 0.83028486,\n",
      "       0.83313343, 0.83133433, 0.83223388, 0.83628186, 0.83163418,\n",
      "       0.83433283, 0.82878561, 0.83388306, 0.83583208, 0.82998501,\n",
      "       0.83718141, 0.83973013, 0.83238381, 0.82998501, 0.83433283,\n",
      "       0.88290855, 0.87526237, 0.87091454, 0.86476762, 0.87946027,\n",
      "       0.87361319, 0.86956522, 0.86341829, 0.87781109, 0.87256372,\n",
      "       0.86941529, 0.86326837, 0.87451274, 0.86821589, 0.86716642,\n",
      "       0.86266867, 0.86881559, 0.86401799, 0.86401799, 0.85907046,\n",
      "       0.84482759, 0.84632684, 0.84557721, 0.85277361, 0.85547226,\n",
      "       0.85382309, 0.84722639, 0.84797601, 0.84917541, 0.84767616,\n",
      "       0.83988006, 0.84857571, 0.84467766, 0.84812594, 0.83658171,\n",
      "       0.84272864, 0.84017991, 0.84422789, 0.84992504, 0.84437781,\n",
      "       0.83853073, 0.83283358, 0.82893553, 0.84002999, 0.83658171,\n",
      "       0.83373313, 0.83598201, 0.83478261, 0.82923538, 0.83808096,\n",
      "       0.83328336, 0.83493253, 0.83508246, 0.84152924, 0.84347826,\n",
      "       0.83703148, 0.83703148, 0.83853073, 0.83328336, 0.83328336,\n",
      "       0.8856072 , 0.87796102, 0.87301349, 0.86686657, 0.88215892,\n",
      "       0.87571214, 0.87106447, 0.86491754, 0.87856072, 0.87331334,\n",
      "       0.87016492, 0.86401799, 0.87481259, 0.86851574, 0.86746627,\n",
      "       0.86296852, 0.86881559, 0.86401799, 0.86401799, 0.85907046,\n",
      "       0.86236882, 0.85892054, 0.84887556, 0.85157421, 0.84272864,\n",
      "       0.85007496, 0.84767616, 0.85067466, 0.84272864, 0.84737631,\n",
      "       0.84302849, 0.84272864, 0.85052474, 0.84647676, 0.84482759,\n",
      "       0.84617691, 0.84092954, 0.84047976, 0.83553223, 0.84122939,\n",
      "       0.83868066, 0.83208396, 0.84377811, 0.84422789, 0.84017991,\n",
      "       0.83628186, 0.83298351, 0.83373313, 0.83493253, 0.83103448,\n",
      "       0.83358321, 0.83328336, 0.84062969, 0.83643178, 0.83313343,\n",
      "       0.83763118, 0.84122939, 0.83028486, 0.84617691, 0.83118441,\n",
      "       0.88785607, 0.8802099 , 0.87526237, 0.86911544, 0.8826087 ,\n",
      "       0.87616192, 0.87151424, 0.86536732, 0.87856072, 0.87331334,\n",
      "       0.87016492, 0.86401799, 0.87481259, 0.86851574, 0.86746627,\n",
      "       0.86296852, 0.86881559, 0.86401799, 0.86401799, 0.85907046,\n",
      "       0.86641679, 0.84857571, 0.85082459, 0.85052474, 0.85217391,\n",
      "       0.85307346, 0.85517241, 0.83988006, 0.84032984, 0.84977511,\n",
      "       0.84932534, 0.84287856, 0.84482759, 0.84962519, 0.85352324,\n",
      "       0.84647676, 0.84992504, 0.84587706, 0.84197901, 0.83583208,\n",
      "       0.84722639, 0.83373313, 0.84227886, 0.83793103, 0.84107946,\n",
      "       0.83763118, 0.83988006, 0.83643178, 0.83793103, 0.83793103,\n",
      "       0.84107946, 0.83328336, 0.83148426, 0.83283358, 0.83253373,\n",
      "       0.83493253, 0.83553223, 0.82698651, 0.82938531, 0.83118441]), 'mean_fit_time': array([0.42682652, 0.40674572, 0.3895957 , 0.40404897, 0.3558722 ,\n",
      "       0.34955153, 0.35665812, 0.35440016, 0.31259074, 0.31548452,\n",
      "       0.30459061, 0.30483699, 0.26815791, 0.26001277, 0.26107879,\n",
      "       0.25289178, 0.22406478, 0.20856514, 0.21688061, 0.21352463,\n",
      "       0.01463118, 0.01531773, 0.01579652, 0.01399956, 0.0137464 ,\n",
      "       0.01288605, 0.01213546, 0.01155438, 0.01065626, 0.00950003,\n",
      "       0.01120472, 0.01176152, 0.00973458, 0.01012316, 0.00997767,\n",
      "       0.00943141, 0.0087863 , 0.00933337, 0.0079648 , 0.00836973,\n",
      "       0.00808878, 0.00877542, 0.00879064, 0.00838261, 0.00706458,\n",
      "       0.00749226, 0.00732622, 0.00685835, 0.00614066, 0.00613127,\n",
      "       0.00715847, 0.00630474, 0.00540581, 0.00548649, 0.00588574,\n",
      "       0.00518746, 0.00525885, 0.00511389, 0.00579972, 0.00537362,\n",
      "       0.06781979, 0.06481891, 0.06310983, 0.06185546, 0.0658092 ,\n",
      "       0.06624179, 0.06143389, 0.06046772, 0.07239776, 0.06206579,\n",
      "       0.06022482, 0.05943618, 0.06249981, 0.06019411, 0.06374593,\n",
      "       0.06168633, 0.06079025, 0.0588902 , 0.05758457, 0.05718913,\n",
      "       0.00514941, 0.00502472, 0.0050653 , 0.00514221, 0.00502262,\n",
      "       0.00516863, 0.00483475, 0.00510378, 0.00478268, 0.00497303,\n",
      "       0.00501208, 0.00497999, 0.00484524, 0.00480251, 0.00482745,\n",
      "       0.00504375, 0.0048871 , 0.0046442 , 0.00480566, 0.0048831 ,\n",
      "       0.00397134, 0.00380564, 0.00370135, 0.00384288, 0.00371847,\n",
      "       0.00380054, 0.0037734 , 0.00372386, 0.00380082, 0.00367875,\n",
      "       0.00373497, 0.00376697, 0.00368762, 0.00369749, 0.00378327,\n",
      "       0.00378728, 0.00363617, 0.0037056 , 0.00363159, 0.00368567,\n",
      "       0.08701844, 0.08690486, 0.08305779, 0.08067012, 0.0839642 ,\n",
      "       0.08166857, 0.08725214, 0.07829032, 0.08254843, 0.08948865,\n",
      "       0.07794676, 0.07690697, 0.08003292, 0.07744741, 0.07606463,\n",
      "       0.07492685, 0.08509378, 0.07525129, 0.07432003, 0.072821  ,\n",
      "       0.00590434, 0.00579824, 0.00579691, 0.00589848, 0.00572143,\n",
      "       0.00577116, 0.00569644, 0.00573821, 0.00559855, 0.00547972,\n",
      "       0.00573926, 0.00570984, 0.00553632, 0.00560098, 0.00557947,\n",
      "       0.00559769, 0.00551066, 0.00576835, 0.00538468, 0.0055449 ,\n",
      "       0.00404968, 0.00398679, 0.00400128, 0.00405293, 0.00416965,\n",
      "       0.00405688, 0.00402122, 0.00407929, 0.00398602, 0.00407262,\n",
      "       0.00404186, 0.0040029 , 0.00401106, 0.00408053, 0.0039535 ,\n",
      "       0.00394926, 0.00398092, 0.0039052 , 0.00407677, 0.00404153,\n",
      "       0.10554156, 0.10251241, 0.09974027, 0.09966588, 0.10233455,\n",
      "       0.10657105, 0.09624753, 0.09587064, 0.09936595, 0.10389862,\n",
      "       0.09447556, 0.09331284, 0.09697661, 0.09400883, 0.09235129,\n",
      "       0.09758406, 0.0970871 , 0.09038596, 0.08909359, 0.08773346,\n",
      "       0.00662236, 0.00630398, 0.00634704, 0.00642605, 0.00639377,\n",
      "       0.00628204, 0.0062686 , 0.00638208, 0.00619817, 0.00602355,\n",
      "       0.00612693, 0.00614924, 0.00630059, 0.0059948 , 0.0059278 ,\n",
      "       0.00575705, 0.00744505, 0.00621061, 0.00586267, 0.0059463 ,\n",
      "       0.00437884, 0.0044126 , 0.00437431, 0.00439892, 0.00428352,\n",
      "       0.00442104, 0.00425277, 0.00431356, 0.00438066, 0.00427494,\n",
      "       0.00440068, 0.00427151, 0.00426474, 0.00436969, 0.00423217,\n",
      "       0.00420365, 0.00417452, 0.00413504, 0.0041492 , 0.00419774,\n",
      "       0.12383566, 0.12739987, 0.11828589, 0.1272017 , 0.11967149,\n",
      "       0.1183826 , 0.12778692, 0.11284122, 0.12945366, 0.11195517,\n",
      "       0.12952409, 0.10801115, 0.11311479, 0.10887046, 0.10713687,\n",
      "       0.10523052, 0.10845375, 0.10426631, 0.10913463, 0.10169072,\n",
      "       0.00713277, 0.00709991, 0.00713739, 0.00694437, 0.00718107,\n",
      "       0.00705576, 0.00672626, 0.00676703, 0.00647187, 0.00663452,\n",
      "       0.00660586, 0.00633936, 0.00665784, 0.00648875, 0.00630908,\n",
      "       0.00621099, 0.0060142 , 0.00628767, 0.00636768, 0.00638566,\n",
      "       0.00488319, 0.00472021, 0.00458236, 0.00475674, 0.00460467,\n",
      "       0.00452895, 0.00466886, 0.00443439, 0.00464396, 0.00452752,\n",
      "       0.00433984, 0.0044611 , 0.00439167, 0.00557222, 0.00586638,\n",
      "       0.00577998, 0.00575466, 0.00462899, 0.00429845, 0.00435061]), 'split2_test_score': array([0.84403119, 0.84703059, 0.84823035, 0.84763047, 0.83923215,\n",
      "       0.84283143, 0.84883023, 0.84523095, 0.84343131, 0.85002999,\n",
      "       0.85122975, 0.84943011, 0.84763047, 0.85302939, 0.85482903,\n",
      "       0.85122975, 0.84163167, 0.85062987, 0.85002999, 0.84943011,\n",
      "       0.85002999, 0.83443311, 0.84523095, 0.85422915, 0.83323335,\n",
      "       0.83803239, 0.82543491, 0.83203359, 0.84763047, 0.84343131,\n",
      "       0.84583083, 0.85182963, 0.84523095, 0.85242951, 0.85122975,\n",
      "       0.83443311, 0.83443311, 0.82843431, 0.83743251, 0.83563287,\n",
      "       0.83503299, 0.82903419, 0.84403119, 0.82483503, 0.83923215,\n",
      "       0.83083383, 0.82783443, 0.84283143, 0.82603479, 0.82963407,\n",
      "       0.83023395, 0.83023395, 0.84163167, 0.82723455, 0.84883023,\n",
      "       0.83323335, 0.82663467, 0.83323335, 0.83683263, 0.82243551,\n",
      "       0.85242951, 0.84943011, 0.85182963, 0.85122975, 0.84583083,\n",
      "       0.84523095, 0.85002999, 0.84823035, 0.84943011, 0.85182963,\n",
      "       0.85302939, 0.85122975, 0.85002999, 0.85062987, 0.85242951,\n",
      "       0.84883023, 0.84823035, 0.85062987, 0.85002999, 0.84943011,\n",
      "       0.84403119, 0.82843431, 0.82423515, 0.83743251, 0.82963407,\n",
      "       0.82903419, 0.83743251, 0.83263347, 0.85602879, 0.84883023,\n",
      "       0.83983203, 0.82723455, 0.82603479, 0.83923215, 0.82903419,\n",
      "       0.83683263, 0.84403119, 0.83263347, 0.83923215, 0.82783443,\n",
      "       0.82423515, 0.81643671, 0.82543491, 0.82723455, 0.82543491,\n",
      "       0.82363527, 0.82903419, 0.82423515, 0.82363527, 0.83383323,\n",
      "       0.81523695, 0.82303539, 0.82483503, 0.82783443, 0.83023395,\n",
      "       0.82663467, 0.83383323, 0.83623275, 0.82963407, 0.83503299,\n",
      "       0.85062987, 0.84763047, 0.85002999, 0.84943011, 0.84343131,\n",
      "       0.84283143, 0.84943011, 0.84703059, 0.85002999, 0.85242951,\n",
      "       0.85362927, 0.85182963, 0.85242951, 0.85242951, 0.85422915,\n",
      "       0.85122975, 0.85002999, 0.84943011, 0.85182963, 0.85122975,\n",
      "       0.85842831, 0.83263347, 0.83383323, 0.84823035, 0.82783443,\n",
      "       0.84103179, 0.83743251, 0.84763047, 0.81883623, 0.82783443,\n",
      "       0.82483503, 0.83143371, 0.84703059, 0.83683263, 0.85062987,\n",
      "       0.82723455, 0.82843431, 0.82363527, 0.83023395, 0.83263347,\n",
      "       0.82663467, 0.81943611, 0.83083383, 0.84043191, 0.82243551,\n",
      "       0.83683263, 0.84283143, 0.83563287, 0.83923215, 0.83263347,\n",
      "       0.83803239, 0.83383323, 0.82303539, 0.83383323, 0.82903419,\n",
      "       0.82483503, 0.83383323, 0.82903419, 0.83263347, 0.82303539,\n",
      "       0.85122975, 0.84763047, 0.85122975, 0.85062987, 0.84463107,\n",
      "       0.84343131, 0.84823035, 0.84823035, 0.85002999, 0.85242951,\n",
      "       0.85362927, 0.85182963, 0.85242951, 0.85302939, 0.85482903,\n",
      "       0.85122975, 0.84643071, 0.85062987, 0.85002999, 0.84943011,\n",
      "       0.83083383, 0.82723455, 0.85602879, 0.83743251, 0.85182963,\n",
      "       0.85062987, 0.83983203, 0.83263347, 0.83923215, 0.82903419,\n",
      "       0.84463107, 0.83923215, 0.84223155, 0.85602879, 0.84763047,\n",
      "       0.83383323, 0.83863227, 0.83803239, 0.82843431, 0.83983203,\n",
      "       0.83503299, 0.82303539, 0.83203359, 0.83323335, 0.82723455,\n",
      "       0.83023395, 0.83083383, 0.82903419, 0.84463107, 0.82663467,\n",
      "       0.84643071, 0.83023395, 0.82243551, 0.83203359, 0.82843431,\n",
      "       0.84163167, 0.83203359, 0.82903419, 0.82363527, 0.83863227,\n",
      "       0.85062987, 0.84703059, 0.84943011, 0.85002999, 0.84403119,\n",
      "       0.84523095, 0.84823035, 0.84643071, 0.84823035, 0.85062987,\n",
      "       0.85182963, 0.85002999, 0.85242951, 0.85302939, 0.85482903,\n",
      "       0.85122975, 0.84163167, 0.84763047, 0.85002999, 0.84943011,\n",
      "       0.81883623, 0.85002999, 0.84523095, 0.84763047, 0.84343131,\n",
      "       0.83263347, 0.85062987, 0.85302939, 0.83443311, 0.84223155,\n",
      "       0.83203359, 0.84403119, 0.82723455, 0.85422915, 0.83263347,\n",
      "       0.83923215, 0.82783443, 0.83203359, 0.83383323, 0.83203359,\n",
      "       0.83203359, 0.82543491, 0.83743251, 0.83443311, 0.84223155,\n",
      "       0.83323335, 0.83623275, 0.85302939, 0.81763647, 0.82723455,\n",
      "       0.84043191, 0.82243551, 0.84643071, 0.83923215, 0.83923215,\n",
      "       0.83683263, 0.82603479, 0.80803839, 0.84223155, 0.83863227]), 'param_max_features': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'mean_test_score': array([0.84059014, 0.84142977, 0.83855104, 0.83651193, 0.84166967,\n",
      "       0.84142977, 0.8425093 , 0.83891088, 0.84118988, 0.84286914,\n",
      "       0.84358882, 0.8402303 , 0.84238935, 0.84574787, 0.84670745,\n",
      "       0.84406861, 0.83891088, 0.84310903, 0.8445484 , 0.84286914,\n",
      "       0.83231378, 0.83423294, 0.83723162, 0.83051457, 0.83459278,\n",
      "       0.8336332 , 0.82439727, 0.83783135, 0.83075447, 0.83663188,\n",
      "       0.83807125, 0.83843109, 0.8356723 , 0.84118988, 0.83663188,\n",
      "       0.83219383, 0.83183399, 0.8336332 , 0.8336332 , 0.83435288,\n",
      "       0.83279357, 0.82739595, 0.82775579, 0.82235816, 0.8313542 ,\n",
      "       0.83015473, 0.82775579, 0.83291352, 0.8252369 , 0.82943505,\n",
      "       0.82751589, 0.82643637, 0.829555  , 0.82943505, 0.8336332 ,\n",
      "       0.82667626, 0.82967494, 0.82667626, 0.83075447, 0.82547679,\n",
      "       0.85186518, 0.84934629, 0.84718724, 0.84418856, 0.84778697,\n",
      "       0.84574787, 0.84670745, 0.84346887, 0.84586782, 0.84586782,\n",
      "       0.8465875 , 0.84322898, 0.84418856, 0.84574787, 0.8468274 ,\n",
      "       0.84406861, 0.8422694 , 0.84418856, 0.84562792, 0.84394866,\n",
      "       0.8356723 , 0.82979489, 0.82847547, 0.83375315, 0.8315941 ,\n",
      "       0.8356723 , 0.83435288, 0.82991484, 0.83723162, 0.83711167,\n",
      "       0.83195394, 0.83039463, 0.827276  , 0.83879093, 0.83003478,\n",
      "       0.83315341, 0.83531246, 0.83183399, 0.83051457, 0.82811563,\n",
      "       0.82859542, 0.82319779, 0.82751589, 0.83243373, 0.82583663,\n",
      "       0.82679621, 0.82787573, 0.82511695, 0.82247811, 0.82547679,\n",
      "       0.82883531, 0.82583663, 0.82775579, 0.82799568, 0.82655632,\n",
      "       0.82559674, 0.82799568, 0.82823558, 0.82571668, 0.827276  ,\n",
      "       0.85066571, 0.84874655, 0.84754708, 0.84442845, 0.84586782,\n",
      "       0.84502819, 0.84634761, 0.84298908, 0.84466835, 0.84550798,\n",
      "       0.84622766, 0.84286914, 0.84370877, 0.84598777, 0.84706729,\n",
      "       0.84442845, 0.84059014, 0.84286914, 0.84490824, 0.84322898,\n",
      "       0.83651193, 0.83747151, 0.8359122 , 0.8336332 , 0.83807125,\n",
      "       0.83555236, 0.83471273, 0.84094998, 0.82907521, 0.83507257,\n",
      "       0.82307785, 0.83147415, 0.83471273, 0.83171405, 0.83699172,\n",
      "       0.83087442, 0.83195394, 0.83255368, 0.83063452, 0.83411299,\n",
      "       0.82811563, 0.82655632, 0.82871537, 0.83087442, 0.82403742,\n",
      "       0.83327336, 0.8293151 , 0.8338731 , 0.82859542, 0.83003478,\n",
      "       0.8293151 , 0.82763584, 0.82487705, 0.83051457, 0.82871537,\n",
      "       0.82739595, 0.83147415, 0.82967494, 0.83015473, 0.82823558,\n",
      "       0.84730718, 0.84634761, 0.84526808, 0.84118988, 0.84418856,\n",
      "       0.84310903, 0.84394866, 0.84083003, 0.84262924, 0.84346887,\n",
      "       0.84418856, 0.84083003, 0.84322898, 0.84562792, 0.8468274 ,\n",
      "       0.84394866, 0.83987046, 0.84310903, 0.8445484 , 0.84286914,\n",
      "       0.83759146, 0.83063452, 0.83771141, 0.83351325, 0.83639199,\n",
      "       0.83303347, 0.83447283, 0.83063452, 0.83699172, 0.83027468,\n",
      "       0.8313542 , 0.83687178, 0.83711167, 0.83987046, 0.83411299,\n",
      "       0.83171405, 0.8336332 , 0.83375315, 0.83171405, 0.83531246,\n",
      "       0.82487705, 0.82619647, 0.82907521, 0.82871537, 0.82715605,\n",
      "       0.82619647, 0.82535684, 0.82775579, 0.82739595, 0.82583663,\n",
      "       0.83207389, 0.82691616, 0.82619647, 0.82787573, 0.83327336,\n",
      "       0.8356723 , 0.83507257, 0.82583663, 0.82559674, 0.83039463,\n",
      "       0.84646755, 0.84514813, 0.84334893, 0.84071009, 0.84406861,\n",
      "       0.84310903, 0.84382872, 0.84047019, 0.8425093 , 0.84334893,\n",
      "       0.84406861, 0.84071009, 0.84322898, 0.84562792, 0.84670745,\n",
      "       0.84406861, 0.83891088, 0.8425093 , 0.8445484 , 0.84286914,\n",
      "       0.83231378, 0.83723162, 0.83207389, 0.83855104, 0.83843109,\n",
      "       0.83171405, 0.83411299, 0.83519252, 0.83039463, 0.83423294,\n",
      "       0.83219383, 0.8338731 , 0.83003478, 0.83987046, 0.83375315,\n",
      "       0.8336332 , 0.82943505, 0.83195394, 0.83519252, 0.83255368,\n",
      "       0.82943505, 0.82343769, 0.82715605, 0.82307785, 0.82619647,\n",
      "       0.83219383, 0.83075447, 0.8293151 , 0.82547679, 0.82667626,\n",
      "       0.82643637, 0.82367758, 0.82943505, 0.82655632, 0.82811563,\n",
      "       0.83207389, 0.82967494, 0.82607653, 0.82943505, 0.82751589]), 'rank_test_score': array([ 93,  83, 104, 124,  82,  83,  77, 100,  85,  70,  56,  96,  80,\n",
      "        24,  12,  46, 100,  65,  36,  70, 172, 145, 114, 202, 141, 155,\n",
      "       292, 110, 196, 122, 108, 106, 128,  85, 122, 174, 183, 155, 155,\n",
      "       143, 168, 255, 247, 300, 192, 209, 247, 167, 288, 220, 252, 270,\n",
      "       219, 220, 155, 264, 216, 264, 196, 284,   1,   3,   8,  41,   5,\n",
      "        24,  12,  57,  21,  21,  15,  61,  41,  24,  10,  46,  81,  41,\n",
      "        27,  51, 128, 215, 237, 152, 189, 128, 143, 214, 114, 117, 180,\n",
      "       205, 258, 103, 211, 165, 133, 183, 202, 240, 235, 296, 252, 171,\n",
      "       277, 263, 245, 289, 299, 284, 231, 277, 247, 243, 267, 282, 243,\n",
      "       238, 281, 258,   2,   4,   6,  39,  21,  33,  17,  69,  35,  30,\n",
      "        19,  70,  55,  20,   9,  39,  93,  70,  34,  61, 124, 113, 127,\n",
      "       155, 108, 132, 139,  88, 229, 137, 297, 190, 139, 185, 119, 194,\n",
      "       180, 169, 199, 147, 240, 267, 232, 194, 293, 163, 226, 150, 235,\n",
      "       211, 226, 251, 290, 202, 232, 255, 190, 216, 209, 238,   7,  17,\n",
      "        31,  85,  41,  65,  51,  89,  76,  57,  41,  89,  61,  27,  10,\n",
      "        51,  97,  65,  36,  70, 112, 199, 111, 162, 126, 166, 142, 199,\n",
      "       119, 208, 192, 121, 117,  97, 147, 185, 155, 152, 185, 133, 290,\n",
      "       272, 229, 232, 260, 272, 287, 247, 255, 277, 177, 262, 272, 245,\n",
      "       163, 128, 137, 277, 282, 205,  16,  32,  59,  91,  46,  65,  54,\n",
      "        95,  77,  59,  46,  91,  61,  27,  12,  46, 100,  77,  36,  70,\n",
      "       172, 114, 177, 104, 106, 185, 147, 135, 205, 145, 174, 150, 211,\n",
      "        97, 152, 155, 220, 180, 135, 169, 220, 295, 260, 297, 272, 174,\n",
      "       196, 226, 284, 264, 270, 294, 220, 267, 240, 177, 216, 276, 220,\n",
      "       252], dtype=int32), 'mean_train_score': array([0.88754962, 0.8804728 , 0.87498518, 0.8701572 , 0.88101235,\n",
      "       0.8750151 , 0.86979736, 0.86577904, 0.87651428, 0.87174653,\n",
      "       0.86751827, 0.86344003, 0.87192651, 0.86736864, 0.86362015,\n",
      "       0.86062135, 0.86766839, 0.86287056, 0.86107123, 0.85825246,\n",
      "       0.8642799 , 0.86344024, 0.86373986, 0.85798281, 0.85231541,\n",
      "       0.85717271, 0.85411412, 0.85522398, 0.85021578, 0.84952637,\n",
      "       0.84886642, 0.85222521, 0.84985585, 0.84856649, 0.84766735,\n",
      "       0.84748667, 0.84451838, 0.84787752, 0.84481765, 0.84002091,\n",
      "       0.85066559, 0.84463791, 0.84943619, 0.8471275 , 0.84328936,\n",
      "       0.84544801, 0.84487761, 0.84418922, 0.8367213 , 0.84182027,\n",
      "       0.84044103, 0.83753186, 0.83765146, 0.83669202, 0.83804069,\n",
      "       0.83489261, 0.83441259, 0.8346829 , 0.83876061, 0.83351373,\n",
      "       0.87678438, 0.87042721, 0.86508951, 0.86023154, 0.87414548,\n",
      "       0.86838812, 0.86326033, 0.85924201, 0.87147663, 0.86697874,\n",
      "       0.86275048, 0.85867224, 0.86904784, 0.86472985, 0.86098136,\n",
      "       0.85798256, 0.86616904, 0.86170106, 0.85990174, 0.85708297,\n",
      "       0.84892651, 0.84427869, 0.84286947, 0.84757704, 0.84307878,\n",
      "       0.84643789, 0.84127976, 0.84107018, 0.84445801, 0.84304881,\n",
      "       0.84118973, 0.83723164, 0.83969026, 0.84074042, 0.83846101,\n",
      "       0.84178991, 0.84262946, 0.83714149, 0.84247939, 0.8354924 ,\n",
      "       0.83450247, 0.83162414, 0.83345374, 0.83504279, 0.83090412,\n",
      "       0.83276388, 0.83141463, 0.83198408, 0.83183395, 0.83372318,\n",
      "       0.83279377, 0.83021471, 0.83426305, 0.83114433, 0.83210397,\n",
      "       0.83174447, 0.83240365, 0.83204419, 0.83030459, 0.83126429,\n",
      "       0.88149216, 0.87468524, 0.8694075 , 0.86451955, 0.87768385,\n",
      "       0.8719265 , 0.8668287 , 0.86281038, 0.87477508, 0.87012727,\n",
      "       0.86589901, 0.86182077, 0.8711169 , 0.86664899, 0.8629005 ,\n",
      "       0.8599017 , 0.86742851, 0.8627806 , 0.8609513 , 0.85813252,\n",
      "       0.85129622, 0.84868678, 0.84910632, 0.84955592, 0.84424785,\n",
      "       0.84682706, 0.84826753, 0.84916655, 0.84583758, 0.84493859,\n",
      "       0.84118981, 0.84766777, 0.84445878, 0.84262912, 0.84409884,\n",
      "       0.84113002, 0.84292943, 0.84092047, 0.84403832, 0.84451844,\n",
      "       0.83525258, 0.83597229, 0.83675246, 0.83831139, 0.83513294,\n",
      "       0.8333631 , 0.83513226, 0.83690245, 0.8347729 , 0.83873112,\n",
      "       0.83603273, 0.8327332 , 0.83396372, 0.8412193 , 0.83702119,\n",
      "       0.83354348, 0.83390276, 0.83552241, 0.83312406, 0.8320442 ,\n",
      "       0.8845809 , 0.87756401, 0.87222636, 0.86736838, 0.88002281,\n",
      "       0.87408554, 0.86883781, 0.8647895 , 0.87597456, 0.87132675,\n",
      "       0.8670985 , 0.86302025, 0.87180658, 0.86733866, 0.86359017,\n",
      "       0.86059137, 0.86748848, 0.86287056, 0.86107123, 0.85825246,\n",
      "       0.85273509, 0.84769671, 0.85030615, 0.85123579, 0.8527954 ,\n",
      "       0.84847677, 0.84886696, 0.8491966 , 0.85135508, 0.8457182 ,\n",
      "       0.84364915, 0.84895721, 0.85114605, 0.84946612, 0.84520816,\n",
      "       0.84406888, 0.84053015, 0.84088951, 0.83948054, 0.84340982,\n",
      "       0.83846091, 0.83654182, 0.83561228, 0.84208926, 0.83495218,\n",
      "       0.83660217, 0.83402303, 0.8390012 , 0.83831116, 0.83237361,\n",
      "       0.83552239, 0.83432284, 0.83660202, 0.8348326 , 0.83702196,\n",
      "       0.8380713 , 0.83480287, 0.83141443, 0.83426266, 0.83423295,\n",
      "       0.88599033, 0.87891349, 0.87354585, 0.86874785, 0.88059259,\n",
      "       0.87459534, 0.8693776 , 0.86532929, 0.8762744 , 0.87162659,\n",
      "       0.86739834, 0.86332009, 0.87183656, 0.86736864, 0.86362015,\n",
      "       0.86062135, 0.86766839, 0.86290054, 0.86107123, 0.85825246,\n",
      "       0.85450431, 0.85729319, 0.8537248 , 0.85258471, 0.85327469,\n",
      "       0.84871675, 0.85087547, 0.85174596, 0.84571849, 0.85006641,\n",
      "       0.84859741, 0.84766662, 0.8447883 , 0.84763649, 0.84919607,\n",
      "       0.84493838, 0.84289936, 0.84544825, 0.84385886, 0.84011086,\n",
      "       0.8408899 , 0.8366621 , 0.84065017, 0.83969051, 0.8382513 ,\n",
      "       0.83876149, 0.83828097, 0.83987047, 0.83837123, 0.83855143,\n",
      "       0.83645225, 0.83519325, 0.83702187, 0.83480293, 0.83294325,\n",
      "       0.83705205, 0.83378351, 0.83324333, 0.83789171, 0.83492251]), 'std_fit_time': array([4.59239130e-02, 3.46011351e-02, 2.90394354e-02, 3.96796991e-02,\n",
      "       2.20844355e-02, 2.27602303e-02, 2.09917493e-02, 1.72348652e-02,\n",
      "       2.49039425e-02, 4.31373788e-02, 2.15283269e-02, 3.97950566e-02,\n",
      "       1.38799509e-02, 2.35206056e-02, 3.15985158e-02, 1.40402934e-02,\n",
      "       3.08648254e-02, 1.66424005e-02, 2.35076250e-02, 2.74806611e-02,\n",
      "       7.78673949e-04, 1.83816220e-03, 8.87988589e-04, 8.03073799e-04,\n",
      "       1.28388807e-03, 1.02030281e-03, 6.99574300e-04, 1.56898698e-03,\n",
      "       1.02472339e-03, 8.12537807e-04, 1.24155507e-03, 1.40158193e-03,\n",
      "       6.58971552e-04, 1.00166185e-03, 9.18542702e-04, 4.39716786e-04,\n",
      "       1.26768949e-03, 1.16137900e-03, 5.10113149e-04, 1.22951793e-03,\n",
      "       6.36282710e-04, 7.04108546e-04, 7.11482069e-04, 9.49125114e-04,\n",
      "       5.59848860e-04, 8.51219819e-04, 1.38002082e-03, 4.89965413e-04,\n",
      "       4.33194037e-04, 1.06946186e-03, 5.66170816e-04, 1.01371613e-03,\n",
      "       5.98630826e-04, 2.57983093e-04, 1.09358896e-03, 5.41235600e-04,\n",
      "       4.49467687e-04, 1.92066397e-04, 7.27836363e-04, 4.40499204e-04,\n",
      "       8.87470411e-04, 9.35694719e-04, 6.59308125e-04, 7.44655181e-04,\n",
      "       4.55037168e-04, 6.43022999e-03, 6.57784746e-04, 5.92727365e-04,\n",
      "       9.61257803e-03, 1.23233690e-03, 9.85186309e-04, 6.81940833e-04,\n",
      "       7.73011634e-04, 7.31110712e-04, 7.59660835e-03, 7.42258140e-03,\n",
      "       4.87092119e-04, 4.15459424e-04, 8.53832083e-04, 5.03166798e-04,\n",
      "       2.59874825e-04, 1.34692732e-04, 3.32556285e-04, 2.92374561e-04,\n",
      "       2.89406869e-04, 1.90314748e-04, 1.30919426e-04, 2.80432972e-04,\n",
      "       1.71155781e-04, 2.39233845e-04, 2.45474102e-04, 1.81188809e-04,\n",
      "       3.13791915e-04, 1.85267308e-04, 1.69313279e-04, 2.36644294e-04,\n",
      "       2.64996947e-04, 1.75324172e-04, 1.38551402e-04, 2.50694541e-04,\n",
      "       1.80249870e-04, 1.12838756e-04, 3.63093884e-05, 7.30514526e-05,\n",
      "       9.66079143e-05, 1.87702912e-04, 1.70625595e-04, 4.77635193e-05,\n",
      "       1.19758998e-04, 1.13445703e-04, 4.87661527e-05, 2.51122087e-04,\n",
      "       7.94542927e-05, 7.37113134e-05, 3.81737925e-04, 1.26631557e-04,\n",
      "       6.99010421e-05, 1.87632762e-04, 1.13945525e-04, 1.22015296e-04,\n",
      "       1.09747631e-03, 4.68526883e-03, 3.04452881e-03, 1.50513458e-03,\n",
      "       9.76755062e-04, 1.17543632e-03, 1.10442145e-02, 9.69561081e-04,\n",
      "       9.49345676e-04, 1.04082883e-02, 1.07370212e-03, 1.08363280e-03,\n",
      "       1.16515030e-03, 1.27087606e-03, 1.18427640e-03, 1.58252147e-03,\n",
      "       1.05824958e-02, 1.11344325e-03, 1.52239321e-03, 1.56363350e-03,\n",
      "       3.83859320e-04, 2.73597577e-04, 2.41743084e-04, 4.05831704e-04,\n",
      "       2.35366338e-04, 3.35541435e-04, 1.29466039e-04, 2.58194020e-04,\n",
      "       2.27085205e-04, 3.12071418e-04, 3.93993650e-04, 1.91660269e-04,\n",
      "       2.91750624e-04, 4.22046503e-04, 4.82445329e-04, 2.78102190e-04,\n",
      "       4.27527675e-04, 3.82397905e-04, 2.65069311e-04, 3.39354389e-04,\n",
      "       9.92477411e-05, 1.20249539e-04, 8.42553313e-05, 2.25989625e-05,\n",
      "       1.32764464e-04, 1.48057853e-04, 5.09407169e-05, 1.75436381e-04,\n",
      "       1.01456740e-04, 1.88783282e-04, 1.87987351e-04, 4.39165728e-05,\n",
      "       1.92075050e-04, 2.69979118e-04, 1.03128909e-04, 7.57580953e-05,\n",
      "       1.69587214e-04, 8.74624641e-05, 1.71297031e-04, 2.17668229e-04,\n",
      "       1.89056380e-03, 2.09547166e-03, 2.51600611e-03, 2.76864890e-03,\n",
      "       1.92865234e-03, 1.35896160e-02, 1.31993673e-03, 1.99359131e-03,\n",
      "       1.56025676e-03, 8.74400786e-03, 1.62791814e-03, 1.83276411e-03,\n",
      "       1.90958087e-03, 1.92985301e-03, 1.86797469e-03, 1.12906115e-02,\n",
      "       7.28091669e-03, 1.83435005e-03, 2.06450985e-03, 2.10673375e-03,\n",
      "       3.52169774e-04, 2.42188001e-04, 2.69007361e-04, 4.22891372e-04,\n",
      "       4.35579211e-04, 2.05088177e-04, 1.92846447e-04, 2.62984646e-04,\n",
      "       4.68187148e-04, 2.76675844e-04, 1.36789730e-04, 1.67745416e-04,\n",
      "       2.87288298e-04, 1.93590718e-04, 2.91817251e-04, 4.02033802e-04,\n",
      "       4.98086379e-04, 1.11914538e-03, 2.34866935e-04, 4.06076960e-04,\n",
      "       1.91409016e-04, 1.53936255e-04, 1.64813809e-04, 1.63415134e-04,\n",
      "       2.12098733e-04, 2.45159758e-04, 1.10704049e-04, 1.09179425e-04,\n",
      "       2.41573884e-04, 4.29967532e-05, 1.74510896e-04, 1.82303146e-04,\n",
      "       3.08829968e-04, 3.59544495e-04, 1.87975292e-04, 1.43451021e-04,\n",
      "       2.78986757e-04, 1.24989707e-04, 1.49344606e-04, 1.00164704e-04,\n",
      "       2.19817474e-03, 1.27750297e-02, 2.18659792e-03, 1.66209571e-02,\n",
      "       2.24997997e-03, 3.14512290e-03, 1.88236966e-02, 3.71117255e-03,\n",
      "       1.21471611e-02, 2.11545179e-03, 1.79433128e-02, 2.91291090e-03,\n",
      "       3.61154496e-03, 3.06388903e-03, 2.54860701e-03, 2.29442976e-03,\n",
      "       2.58344451e-03, 1.99839998e-03, 1.07132922e-02, 1.87985866e-03,\n",
      "       3.28817030e-04, 3.98936409e-04, 4.13418630e-04, 4.18624529e-04,\n",
      "       3.04222802e-04, 1.62193270e-04, 3.07417881e-04, 2.69553097e-04,\n",
      "       1.28183638e-04, 2.64877329e-04, 3.20806706e-04, 3.57025510e-04,\n",
      "       5.08829824e-04, 1.43840946e-04, 2.24921181e-04, 3.09953924e-04,\n",
      "       2.86991668e-04, 1.74815266e-04, 3.02944483e-04, 1.99270790e-04,\n",
      "       2.58826823e-04, 2.51232100e-04, 2.75893274e-04, 3.43669392e-04,\n",
      "       1.24408962e-04, 1.85384905e-04, 5.11258535e-04, 8.29466974e-05,\n",
      "       3.45328268e-04, 1.81706581e-04, 4.91301039e-05, 1.29235837e-04,\n",
      "       1.28375066e-04, 6.45461256e-04, 1.10992962e-04, 1.55769059e-04,\n",
      "       1.35963358e-04, 5.84834012e-04, 9.58503180e-05, 1.19437990e-04]), 'split1_train_score': array([0.88648973, 0.87884241, 0.87479382, 0.87074524, 0.87974209,\n",
      "       0.87449393, 0.86984555, 0.86654671, 0.87389414, 0.86969561,\n",
      "       0.86639676, 0.86309792, 0.86759634, 0.86354776, 0.86069876,\n",
      "       0.85844954, 0.86474734, 0.86039886, 0.85934923, 0.85710001,\n",
      "       0.86654671, 0.86444744, 0.86459739, 0.85575049, 0.85080222,\n",
      "       0.86009897, 0.85575049, 0.84750337, 0.85320138, 0.84855301,\n",
      "       0.84405458, 0.84450442, 0.84855301, 0.85020243, 0.8520018 ,\n",
      "       0.84960264, 0.84390463, 0.84945269, 0.85275154, 0.83415804,\n",
      "       0.84750337, 0.83475783, 0.85050232, 0.8488529 , 0.83835658,\n",
      "       0.84375469, 0.83760684, 0.85230169, 0.83520768, 0.84300495,\n",
      "       0.84450442, 0.84465437, 0.83640726, 0.84510421, 0.8340081 ,\n",
      "       0.83100915, 0.8337082 , 0.82860999, 0.83025941, 0.83565752,\n",
      "       0.87704303, 0.86954566, 0.86534713, 0.86129855, 0.87374419,\n",
      "       0.86849603, 0.86384765, 0.86054881, 0.86984555, 0.86564702,\n",
      "       0.86234818, 0.85904933, 0.86654671, 0.86249813, 0.85964912,\n",
      "       0.85739991, 0.8642975 , 0.85994902, 0.85889939, 0.85665017,\n",
      "       0.84975259, 0.84540411, 0.83880642, 0.84675364, 0.83790673,\n",
      "       0.84975259, 0.83700705, 0.84645374, 0.83865647, 0.84030589,\n",
      "       0.84525416, 0.83640726, 0.83805668, 0.84150547, 0.84015595,\n",
      "       0.84090568, 0.83625731, 0.83940621, 0.84510421, 0.8340081 ,\n",
      "       0.83595741, 0.83115909, 0.8337082 , 0.84510421, 0.82516119,\n",
      "       0.83100915, 0.83535762, 0.83580747, 0.83025941, 0.83490778,\n",
      "       0.83205878, 0.82965962, 0.8305593 , 0.83100915, 0.82980957,\n",
      "       0.82666067, 0.83040936, 0.83070925, 0.83430799, 0.82920978,\n",
      "       0.88184136, 0.87449393, 0.8702954 , 0.86609687, 0.87749288,\n",
      "       0.87224471, 0.86759634, 0.8642975 , 0.8728445 , 0.86864597,\n",
      "       0.86534713, 0.86204828, 0.86744639, 0.86339781, 0.86054881,\n",
      "       0.8582996 , 0.86459739, 0.86024891, 0.85919928, 0.85695007,\n",
      "       0.85275154, 0.85095217, 0.8517019 , 0.84270505, 0.84075574,\n",
      "       0.84405458, 0.85305143, 0.84495427, 0.84390463, 0.84690358,\n",
      "       0.83805668, 0.85065227, 0.84750337, 0.840006  , 0.85440096,\n",
      "       0.83505773, 0.85710001, 0.84540411, 0.84855301, 0.84195532,\n",
      "       0.83415804, 0.84045584, 0.842855  , 0.837157  , 0.83355825,\n",
      "       0.83355825, 0.82860999, 0.83340831, 0.83580747, 0.8365572 ,\n",
      "       0.83595741, 0.82831009, 0.82995951, 0.83325836, 0.83115909,\n",
      "       0.84180537, 0.8365572 , 0.83325836, 0.83175888, 0.82831009,\n",
      "       0.88439046, 0.87674314, 0.87254461, 0.86834608, 0.87869246,\n",
      "       0.87344429, 0.86879592, 0.86549708, 0.87374419, 0.86954566,\n",
      "       0.86624681, 0.86294797, 0.86759634, 0.86354776, 0.86069876,\n",
      "       0.85844954, 0.86474734, 0.86039886, 0.85934923, 0.85710001,\n",
      "       0.85380117, 0.84615385, 0.8460039 , 0.85155196, 0.8548508 ,\n",
      "       0.84675364, 0.84180537, 0.85635028, 0.85275154, 0.84930274,\n",
      "       0.842855  , 0.84465437, 0.85395112, 0.85020243, 0.84630379,\n",
      "       0.84195532, 0.84375469, 0.8397061 , 0.83955616, 0.84255511,\n",
      "       0.83820663, 0.83700705, 0.8340081 , 0.83955616, 0.83385815,\n",
      "       0.84075574, 0.83490778, 0.84300495, 0.83670715, 0.83220873,\n",
      "       0.8365572 , 0.83550757, 0.82995951, 0.83115909, 0.840006  ,\n",
      "       0.83895637, 0.83940621, 0.82935972, 0.83595741, 0.83355825,\n",
      "       0.88559004, 0.87794272, 0.87359424, 0.86984555, 0.8794422 ,\n",
      "       0.87419403, 0.86954566, 0.86624681, 0.87389414, 0.86969561,\n",
      "       0.86639676, 0.86309792, 0.86759634, 0.86354776, 0.86069876,\n",
      "       0.85844954, 0.86474734, 0.86039886, 0.85934923, 0.85710001,\n",
      "       0.85110211, 0.86279802, 0.8551507 , 0.84705353, 0.85575049,\n",
      "       0.85305143, 0.85080222, 0.86204828, 0.85080222, 0.85320138,\n",
      "       0.85125206, 0.84525416, 0.84480432, 0.84900285, 0.85050232,\n",
      "       0.84405458, 0.84840306, 0.84825311, 0.85185185, 0.84780327,\n",
      "       0.840006  , 0.84195532, 0.83595741, 0.83880642, 0.83505773,\n",
      "       0.84630379, 0.837157  , 0.83505773, 0.845704  , 0.84435448,\n",
      "       0.83850652, 0.83430799, 0.84180537, 0.83835658, 0.82995951,\n",
      "       0.83160894, 0.83850652, 0.84015595, 0.84060579, 0.83940621]), 'split4_test_score': array([0.84813926, 0.84453782, 0.84033613, 0.84093637, 0.85654262,\n",
      "       0.85294118, 0.85054022, 0.8487395 , 0.8607443 , 0.85354142,\n",
      "       0.85114046, 0.84933974, 0.8577431 , 0.85534214, 0.85234094,\n",
      "       0.85234094, 0.85834334, 0.85414166, 0.85354142, 0.85234094,\n",
      "       0.84033613, 0.84273709, 0.84993998, 0.83313325, 0.84933974,\n",
      "       0.84033613, 0.83793517, 0.85054022, 0.83913565, 0.84333733,\n",
      "       0.84033613, 0.83913565, 0.83793517, 0.84033613, 0.82773109,\n",
      "       0.84693878, 0.84693878, 0.83853541, 0.84633854, 0.83673469,\n",
      "       0.83493397, 0.82953181, 0.84753902, 0.81632653, 0.83133253,\n",
      "       0.8457383 , 0.84093637, 0.84093637, 0.83133253, 0.83553421,\n",
      "       0.82773109, 0.83913565, 0.83973589, 0.83553421, 0.83253301,\n",
      "       0.82893157, 0.84333733, 0.83733493, 0.82893157, 0.82713085,\n",
      "       0.85834334, 0.85294118, 0.8487395 , 0.84753902, 0.85534214,\n",
      "       0.8517407 , 0.84933974, 0.84753902, 0.85894358, 0.8517407 ,\n",
      "       0.84933974, 0.84753902, 0.8547419 , 0.85234094, 0.84933974,\n",
      "       0.84933974, 0.85534214, 0.85114046, 0.85054022, 0.84933974,\n",
      "       0.83373349, 0.82953181, 0.83553421, 0.84453782, 0.83913565,\n",
      "       0.83493397, 0.84513806, 0.83913565, 0.83433373, 0.83673469,\n",
      "       0.83253301, 0.84153661, 0.84393758, 0.83613445, 0.83313325,\n",
      "       0.83073229, 0.83733493, 0.84753902, 0.83253301, 0.84153661,\n",
      "       0.82833133, 0.82713085, 0.82412965, 0.84033613, 0.81812725,\n",
      "       0.82653061, 0.82533013, 0.82232893, 0.82292917, 0.82653061,\n",
      "       0.83073229, 0.83433373, 0.83673469, 0.82593037, 0.83013205,\n",
      "       0.82352941, 0.83013205, 0.82893157, 0.82713085, 0.82472989,\n",
      "       0.85714286, 0.84993998, 0.8487395 , 0.84813926, 0.85654262,\n",
      "       0.85294118, 0.85054022, 0.8487395 , 0.86014406, 0.85294118,\n",
      "       0.85054022, 0.8487395 , 0.85654262, 0.85414166, 0.85114046,\n",
      "       0.85114046, 0.85714286, 0.85294118, 0.85234094, 0.85114046,\n",
      "       0.82953181, 0.8487395 , 0.83493397, 0.83673469, 0.84513806,\n",
      "       0.84273709, 0.83373349, 0.84153661, 0.83553421, 0.83793517,\n",
      "       0.83133253, 0.83973589, 0.83553421, 0.83253301, 0.83733493,\n",
      "       0.84333733, 0.83373349, 0.83313325, 0.82833133, 0.8457383 ,\n",
      "       0.82593037, 0.82412965, 0.83193277, 0.83073229, 0.82653061,\n",
      "       0.84093637, 0.82593037, 0.82953181, 0.82653061, 0.83433373,\n",
      "       0.82713085, 0.83073229, 0.82593037, 0.84333733, 0.83313325,\n",
      "       0.82593037, 0.82893157, 0.82953181, 0.82713085, 0.82773109,\n",
      "       0.85714286, 0.85354142, 0.84933974, 0.84633854, 0.85834334,\n",
      "       0.8547419 , 0.85234094, 0.85054022, 0.86134454, 0.85414166,\n",
      "       0.8517407 , 0.84993998, 0.8577431 , 0.85534214, 0.85234094,\n",
      "       0.85234094, 0.85834334, 0.85414166, 0.85354142, 0.85234094,\n",
      "       0.83433373, 0.84033613, 0.84213685, 0.83493397, 0.83793517,\n",
      "       0.83253301, 0.83613445, 0.82593037, 0.85534214, 0.84213685,\n",
      "       0.83073229, 0.83973589, 0.83133253, 0.85054022, 0.83313325,\n",
      "       0.83853541, 0.83793517, 0.84513806, 0.84273709, 0.82893157,\n",
      "       0.83133253, 0.83373349, 0.82412965, 0.83313325, 0.83553421,\n",
      "       0.82593037, 0.81752701, 0.82412965, 0.83073229, 0.82292917,\n",
      "       0.83013205, 0.82593037, 0.83193277, 0.83073229, 0.83673469,\n",
      "       0.83613445, 0.83073229, 0.82713085, 0.82653061, 0.83193277,\n",
      "       0.85654262, 0.8547419 , 0.85054022, 0.84753902, 0.85954382,\n",
      "       0.85594238, 0.85354142, 0.8517407 , 0.86254502, 0.85534214,\n",
      "       0.85294118, 0.85114046, 0.8577431 , 0.85534214, 0.85234094,\n",
      "       0.85234094, 0.85834334, 0.85414166, 0.85354142, 0.85234094,\n",
      "       0.83613445, 0.83853541, 0.84513806, 0.83733493, 0.8487395 ,\n",
      "       0.84033613, 0.83433373, 0.82893157, 0.82833133, 0.84333733,\n",
      "       0.83493397, 0.8517407 , 0.84393758, 0.8457383 , 0.84093637,\n",
      "       0.82833133, 0.82893157, 0.84453782, 0.84213685, 0.83433373,\n",
      "       0.83073229, 0.82953181, 0.82352941, 0.82593037, 0.82292917,\n",
      "       0.83433373, 0.82472989, 0.83613445, 0.83193277, 0.82412965,\n",
      "       0.82292917, 0.82352941, 0.82533013, 0.82833133, 0.82112845,\n",
      "       0.83193277, 0.82533013, 0.83733493, 0.82352941, 0.82713085]), 'split4_train_score': array([0.88562434, 0.88037775, 0.87378204, 0.87183331, 0.87992805,\n",
      "       0.87393194, 0.86838555, 0.86718633, 0.87588068, 0.8710838 ,\n",
      "       0.86748613, 0.8655374 , 0.86973467, 0.8656873 , 0.86238945,\n",
      "       0.86193974, 0.86733623, 0.86343876, 0.86163993, 0.86044071,\n",
      "       0.86178984, 0.85894169, 0.8656873 , 0.853845  , 0.85204617,\n",
      "       0.85819218, 0.85219607, 0.86044071, 0.84904812, 0.84964773,\n",
      "       0.84170289, 0.85084695, 0.85324539, 0.84470094, 0.84125319,\n",
      "       0.85564383, 0.85219607, 0.84500075, 0.85549393, 0.83450757,\n",
      "       0.85054714, 0.85024734, 0.85024734, 0.84575026, 0.84275221,\n",
      "       0.84605007, 0.85429471, 0.84020387, 0.84290211, 0.84080348,\n",
      "       0.83480738, 0.8360066 , 0.84035377, 0.83405786, 0.84260231,\n",
      "       0.83690601, 0.8361565 , 0.83585669, 0.84095338, 0.82746215,\n",
      "       0.87543097, 0.87018438, 0.86388847, 0.86193974, 0.87273272,\n",
      "       0.86673662, 0.86119023, 0.85999101, 0.87003448, 0.8652376 ,\n",
      "       0.86163993, 0.8596912 , 0.86673662, 0.86268925, 0.8593914 ,\n",
      "       0.85894169, 0.8652376 , 0.86134013, 0.8595413 , 0.85834208,\n",
      "       0.8479988 , 0.84619997, 0.84095338, 0.84874831, 0.84485085,\n",
      "       0.84335182, 0.84440114, 0.83855494, 0.84590016, 0.83960426,\n",
      "       0.83840504, 0.83930445, 0.84305202, 0.84080348, 0.83855494,\n",
      "       0.83465747, 0.83825513, 0.84545046, 0.83900465, 0.83675611,\n",
      "       0.83735572, 0.82866137, 0.83420776, 0.83570679, 0.83405786,\n",
      "       0.83330835, 0.8247639 , 0.83076001, 0.83225903, 0.8306101 ,\n",
      "       0.8306101 , 0.83225903, 0.83795533, 0.82896118, 0.83345825,\n",
      "       0.82746215, 0.82971069, 0.8304602 , 0.82866137, 0.82836156,\n",
      "       0.88097736, 0.87513116, 0.86913506, 0.86718633, 0.87678009,\n",
      "       0.87078399, 0.8652376 , 0.86403838, 0.87408185, 0.86928496,\n",
      "       0.8656873 , 0.86373857, 0.86853545, 0.86448808, 0.86119023,\n",
      "       0.86074052, 0.86703643, 0.86313896, 0.86134013, 0.86014091,\n",
      "       0.84425124, 0.85024734, 0.85129666, 0.85519412, 0.85279568,\n",
      "       0.84590016, 0.83885474, 0.84874831, 0.85309549, 0.84365163,\n",
      "       0.84425124, 0.84365163, 0.84035377, 0.84125319, 0.84155299,\n",
      "       0.8423025 , 0.84245241, 0.83450757, 0.84440114, 0.84739919,\n",
      "       0.83240893, 0.83720582, 0.83495728, 0.83795533, 0.83240893,\n",
      "       0.8363064 , 0.83555689, 0.83120971, 0.83150952, 0.84170289,\n",
      "       0.83090991, 0.8361565 , 0.8304602 , 0.85009744, 0.83900465,\n",
      "       0.82881127, 0.83690601, 0.83345825, 0.82956079, 0.82986059,\n",
      "       0.8829261 , 0.87767951, 0.8712337 , 0.86943487, 0.87857892,\n",
      "       0.87258282, 0.86703643, 0.86583721, 0.87528107, 0.87048419,\n",
      "       0.86688652, 0.86493779, 0.86958477, 0.8655374 , 0.86223954,\n",
      "       0.86178984, 0.86733623, 0.86343876, 0.86163993, 0.86044071,\n",
      "       0.84634987, 0.84739919, 0.84754909, 0.84619997, 0.84754909,\n",
      "       0.84515065, 0.84395143, 0.84305202, 0.85834208, 0.84515065,\n",
      "       0.84380153, 0.84709939, 0.84979763, 0.84904812, 0.84050367,\n",
      "       0.84260231, 0.84260231, 0.85174636, 0.84470094, 0.83300854,\n",
      "       0.84080348, 0.84365163, 0.83315845, 0.84365163, 0.83750562,\n",
      "       0.83420776, 0.83240893, 0.83825513, 0.83420776, 0.83585669,\n",
      "       0.83150952, 0.83690601, 0.84020387, 0.83555689, 0.83735572,\n",
      "       0.83570679, 0.83165942, 0.82956079, 0.82791186, 0.83435767,\n",
      "       0.88337581, 0.87797931, 0.8715335 , 0.86973467, 0.87887873,\n",
      "       0.87288263, 0.86733623, 0.86613701, 0.87573077, 0.87093389,\n",
      "       0.86733623, 0.8653875 , 0.86973467, 0.8656873 , 0.86238945,\n",
      "       0.86193974, 0.86733623, 0.86343876, 0.86163993, 0.86044071,\n",
      "       0.84709939, 0.85579373, 0.85444461, 0.85654325, 0.85159646,\n",
      "       0.84575026, 0.84485085, 0.84500075, 0.84140309, 0.84470094,\n",
      "       0.84170289, 0.85444461, 0.84919802, 0.85159646, 0.85189627,\n",
      "       0.84395143, 0.83975416, 0.84739919, 0.84664968, 0.83570679,\n",
      "       0.83885474, 0.83315845, 0.83885474, 0.83915455, 0.83450757,\n",
      "       0.83525708, 0.83780543, 0.84095338, 0.83810523, 0.83675611,\n",
      "       0.82821166, 0.83076001, 0.83240893, 0.82956079, 0.83390796,\n",
      "       0.83405786, 0.8304602 , 0.83690601, 0.83375806, 0.83780543]), 'mean_score_time': array([0.00149302, 0.00129056, 0.00133591, 0.00128388, 0.00117459,\n",
      "       0.00118079, 0.00120687, 0.00134573, 0.0011919 , 0.00114455,\n",
      "       0.00115299, 0.00118723, 0.00110297, 0.00109715, 0.00108991,\n",
      "       0.00114627, 0.00105171, 0.00103331, 0.00109172, 0.00103188,\n",
      "       0.00114164, 0.00114589, 0.00119705, 0.00112677, 0.00116911,\n",
      "       0.00109477, 0.00107465, 0.00103621, 0.00100017, 0.00098453,\n",
      "       0.00104342, 0.00105996, 0.00098958, 0.00102258, 0.00103254,\n",
      "       0.00099406, 0.00097041, 0.00103946, 0.0009274 , 0.00094581,\n",
      "       0.00115995, 0.00121608, 0.001197  , 0.00116463, 0.00106406,\n",
      "       0.00111642, 0.00111504, 0.0010601 , 0.00099545, 0.00097446,\n",
      "       0.00108171, 0.00104337, 0.00094738, 0.00094433, 0.00098968,\n",
      "       0.00092254, 0.00094285, 0.0009161 , 0.00096898, 0.00096712,\n",
      "       0.00082502, 0.00079618, 0.00078349, 0.00081692, 0.00079703,\n",
      "       0.00082707, 0.00080824, 0.00079942, 0.00089035, 0.00080481,\n",
      "       0.00079608, 0.00082397, 0.00081539, 0.00082135, 0.00091515,\n",
      "       0.00082307, 0.00080299, 0.00082011, 0.00080123, 0.00079575,\n",
      "       0.00080738, 0.00082207, 0.00081673, 0.00082083, 0.00081286,\n",
      "       0.0007966 , 0.00080953, 0.00081983, 0.00079722, 0.00082607,\n",
      "       0.00081754, 0.00081148, 0.00081334, 0.00081677, 0.00079255,\n",
      "       0.00081873, 0.00081735, 0.00080638, 0.00079842, 0.00081458,\n",
      "       0.0008153 , 0.00080485, 0.00082431, 0.00080414, 0.00080895,\n",
      "       0.00079446, 0.00081382, 0.00082221, 0.00080733, 0.00081596,\n",
      "       0.00080338, 0.00083933, 0.00080209, 0.00080829, 0.00080276,\n",
      "       0.0008028 , 0.00079603, 0.00080185, 0.00079226, 0.00080614,\n",
      "       0.00082955, 0.00088744, 0.00082865, 0.00083065, 0.00082488,\n",
      "       0.00082655, 0.00092468, 0.00083928, 0.00083952, 0.00092001,\n",
      "       0.00084739, 0.00082779, 0.00082874, 0.00083666, 0.00082231,\n",
      "       0.0008245 , 0.00092702, 0.00083838, 0.00082793, 0.00083513,\n",
      "       0.00084133, 0.00083966, 0.00084057, 0.0008285 , 0.0008348 ,\n",
      "       0.00083504, 0.00083256, 0.00084181, 0.00084138, 0.00082111,\n",
      "       0.00084147, 0.00082293, 0.00082288, 0.00081182, 0.00082078,\n",
      "       0.00082569, 0.00082765, 0.00084453, 0.0008389 , 0.00082598,\n",
      "       0.00083275, 0.00082817, 0.00084271, 0.00081892, 0.00082164,\n",
      "       0.00083785, 0.0008347 , 0.00083566, 0.00083814, 0.00082002,\n",
      "       0.00083179, 0.00082312, 0.00081429, 0.00083213, 0.00081539,\n",
      "       0.00082855, 0.00082226, 0.00081654, 0.00081873, 0.00083628,\n",
      "       0.00085688, 0.00085049, 0.00085716, 0.00095191, 0.00084062,\n",
      "       0.00093012, 0.00083122, 0.00086474, 0.00084982, 0.00090013,\n",
      "       0.00084105, 0.00085349, 0.00087609, 0.00084715, 0.00086551,\n",
      "       0.00095835, 0.00084233, 0.00084906, 0.00085859, 0.00084357,\n",
      "       0.00084476, 0.00086904, 0.00085449, 0.00085344, 0.00085888,\n",
      "       0.00086074, 0.00084205, 0.00083985, 0.00085025, 0.00084219,\n",
      "       0.00085516, 0.00084496, 0.00088406, 0.00084248, 0.00084934,\n",
      "       0.0008419 , 0.00101018, 0.00088243, 0.00083256, 0.0008431 ,\n",
      "       0.00085402, 0.00084863, 0.00082784, 0.0008347 , 0.00083709,\n",
      "       0.00083914, 0.00084686, 0.00083623, 0.00086026, 0.00084181,\n",
      "       0.00085683, 0.00085621, 0.00082941, 0.00085506, 0.00084033,\n",
      "       0.00083609, 0.00083661, 0.00082951, 0.00084629, 0.00085344,\n",
      "       0.0008884 , 0.00093889, 0.00087409, 0.00097156, 0.00088329,\n",
      "       0.00092258, 0.00092382, 0.00091066, 0.00092359, 0.00091581,\n",
      "       0.00097504, 0.00087504, 0.00087466, 0.00087051, 0.00086894,\n",
      "       0.00085998, 0.00088654, 0.00089102, 0.00087519, 0.00086179,\n",
      "       0.00086141, 0.0008729 , 0.00088735, 0.00087538, 0.00088024,\n",
      "       0.00087571, 0.00087466, 0.00086532, 0.00087013, 0.00086346,\n",
      "       0.00086756, 0.00087347, 0.00088673, 0.0008718 , 0.00085778,\n",
      "       0.00086665, 0.00086904, 0.00087008, 0.00086737, 0.0008688 ,\n",
      "       0.00088816, 0.00087509, 0.00087152, 0.00087395, 0.00088067,\n",
      "       0.0009129 , 0.00086432, 0.00087061, 0.00087409, 0.0008719 ,\n",
      "       0.00086694, 0.00088115, 0.00087676, 0.00105338, 0.00108585,\n",
      "       0.00108109, 0.00109777, 0.00086064, 0.00085692, 0.00086656]), 'split3_test_score': array([0.83503299, 0.84223155, 0.83683263, 0.83383323, 0.83743251,\n",
      "       0.84163167, 0.84103179, 0.83563287, 0.83743251, 0.84643071,\n",
      "       0.84403119, 0.83863227, 0.83383323, 0.84823035, 0.84763047,\n",
      "       0.84283143, 0.83023395, 0.84343131, 0.84343131, 0.84163167,\n",
      "       0.83743251, 0.83203359, 0.83263347, 0.82543491, 0.83083383,\n",
      "       0.83323335, 0.81643671, 0.84103179, 0.82783443, 0.83563287,\n",
      "       0.84523095, 0.83563287, 0.83563287, 0.83803239, 0.83503299,\n",
      "       0.84463107, 0.82303539, 0.82903419, 0.82303539, 0.83503299,\n",
      "       0.83863227, 0.82963407, 0.82183563, 0.83923215, 0.82603479,\n",
      "       0.83203359, 0.82903419, 0.82543491, 0.83023395, 0.83083383,\n",
      "       0.82963407, 0.82063587, 0.82003599, 0.82723455, 0.83143371,\n",
      "       0.82543491, 0.83503299, 0.82183563, 0.83203359, 0.83203359,\n",
      "       0.85002999, 0.84943011, 0.84583083, 0.84043191, 0.84763047,\n",
      "       0.84703059, 0.84583083, 0.84043191, 0.84343131, 0.84823035,\n",
      "       0.84583083, 0.84043191, 0.83623275, 0.84643071, 0.84583083,\n",
      "       0.84103179, 0.83443311, 0.84343131, 0.84343131, 0.84163167,\n",
      "       0.82363527, 0.82423515, 0.82903419, 0.82723455, 0.84103179,\n",
      "       0.83863227, 0.83023395, 0.84103179, 0.83023395, 0.84343131,\n",
      "       0.83323335, 0.82783443, 0.83143371, 0.83743251, 0.82663467,\n",
      "       0.83323335, 0.83143371, 0.82363527, 0.83683263, 0.83143371,\n",
      "       0.82783443, 0.82423515, 0.82363527, 0.83443311, 0.83563287,\n",
      "       0.82723455, 0.82363527, 0.83143371, 0.82243551, 0.82363527,\n",
      "       0.83443311, 0.82063587, 0.83083383, 0.83083383, 0.82363527,\n",
      "       0.83323335, 0.83263347, 0.82603479, 0.82783443, 0.83143371,\n",
      "       0.85062987, 0.85362927, 0.85182963, 0.84643071, 0.84403119,\n",
      "       0.84823035, 0.84703059, 0.84163167, 0.84103179, 0.85002999,\n",
      "       0.84763047, 0.84223155, 0.83383323, 0.84823035, 0.84763047,\n",
      "       0.84283143, 0.83023395, 0.84343131, 0.84343131, 0.84163167,\n",
      "       0.82723455, 0.83983203, 0.82843431, 0.83503299, 0.84403119,\n",
      "       0.84343131, 0.83263347, 0.83563287, 0.82303539, 0.83743251,\n",
      "       0.81583683, 0.82903419, 0.82483503, 0.83863227, 0.83083383,\n",
      "       0.83383323, 0.83443311, 0.83983203, 0.83503299, 0.82603479,\n",
      "       0.82663467, 0.82723455, 0.82303539, 0.83023395, 0.82663467,\n",
      "       0.82963407, 0.82783443, 0.82603479, 0.82783443, 0.82603479,\n",
      "       0.83263347, 0.83023395, 0.82003599, 0.83743251, 0.83443311,\n",
      "       0.83323335, 0.83623275, 0.83623275, 0.82423515, 0.83323335,\n",
      "       0.83623275, 0.84283143, 0.84223155, 0.83443311, 0.83803239,\n",
      "       0.84163167, 0.84103179, 0.83563287, 0.83743251, 0.84643071,\n",
      "       0.84403119, 0.83863227, 0.83383323, 0.84823035, 0.84763047,\n",
      "       0.84283143, 0.83023395, 0.84343131, 0.84343131, 0.84163167,\n",
      "       0.84823035, 0.83383323, 0.83203359, 0.82903419, 0.83083383,\n",
      "       0.82543491, 0.83923215, 0.83923215, 0.82603479, 0.83623275,\n",
      "       0.81883623, 0.83203359, 0.83503299, 0.82483503, 0.82723455,\n",
      "       0.82963407, 0.83383323, 0.82963407, 0.82483503, 0.83323335,\n",
      "       0.81823635, 0.82663467, 0.83083383, 0.83263347, 0.82903419,\n",
      "       0.83143371, 0.82603479, 0.82303539, 0.82123575, 0.83083383,\n",
      "       0.83143371, 0.82903419, 0.83143371, 0.83023395, 0.83083383,\n",
      "       0.83443311, 0.84043191, 0.82663467, 0.82903419, 0.82543491,\n",
      "       0.83863227, 0.84343131, 0.84043191, 0.83623275, 0.83803239,\n",
      "       0.84163167, 0.84103179, 0.83563287, 0.83743251, 0.84643071,\n",
      "       0.84403119, 0.83863227, 0.83383323, 0.84823035, 0.84763047,\n",
      "       0.84283143, 0.83023395, 0.84343131, 0.84343131, 0.84163167,\n",
      "       0.83743251, 0.83203359, 0.80983803, 0.83443311, 0.84703059,\n",
      "       0.83263347, 0.83143371, 0.82363527, 0.82483503, 0.82543491,\n",
      "       0.82783443, 0.83983203, 0.82183563, 0.83323335, 0.84043191,\n",
      "       0.82903419, 0.83383323, 0.82963407, 0.83863227, 0.82783443,\n",
      "       0.83263347, 0.83143371, 0.82663467, 0.81763647, 0.82783443,\n",
      "       0.83023395, 0.83683263, 0.82483503, 0.82723455, 0.82183563,\n",
      "       0.83023395, 0.82903419, 0.82843431, 0.82423515, 0.83563287,\n",
      "       0.83383323, 0.82843431, 0.82483503, 0.82423515, 0.82063587]), 'std_test_score': array([0.00575022, 0.00502743, 0.00629538, 0.00712771, 0.0074732 ,\n",
      "       0.00677415, 0.00630096, 0.00710307, 0.01067335, 0.00913503,\n",
      "       0.00690511, 0.00798371, 0.00931283, 0.00869192, 0.00668515,\n",
      "       0.00682341, 0.01066866, 0.00849572, 0.00657601, 0.00729178,\n",
      "       0.0134325 , 0.00450244, 0.00874155, 0.01378215, 0.00751807,\n",
      "       0.00635799, 0.00896787, 0.00752089, 0.01159243, 0.00697592,\n",
      "       0.00830154, 0.00772788, 0.00670991, 0.00628501, 0.00989054,\n",
      "       0.0131302 , 0.00839629, 0.00432175, 0.00792179, 0.00241527,\n",
      "       0.00500766, 0.00454867, 0.01518251, 0.01029353, 0.0082687 ,\n",
      "       0.00923013, 0.00787653, 0.0084113 , 0.00610485, 0.00481127,\n",
      "       0.00684931, 0.00736305, 0.01061714, 0.00517534, 0.00878184,\n",
      "       0.00489129, 0.00844598, 0.0071617 , 0.0053953 , 0.00569068,\n",
      "       0.00382657, 0.00238392, 0.00311578, 0.00443431, 0.00458923,\n",
      "       0.00355636, 0.00274728, 0.00362778, 0.00784178, 0.00634637,\n",
      "       0.00414198, 0.00524129, 0.00714471, 0.00570296, 0.00369281,\n",
      "       0.00416465, 0.00814862, 0.00585628, 0.00384266, 0.00453365,\n",
      "       0.00696593, 0.00351321, 0.00384081, 0.00744075, 0.00726804,\n",
      "       0.00434127, 0.00662754, 0.00981095, 0.00986162, 0.00833253,\n",
      "       0.00472201, 0.00610581, 0.00996701, 0.00211099, 0.00324308,\n",
      "       0.00243005, 0.00607735, 0.0085297 , 0.0074322 , 0.00919533,\n",
      "       0.00276892, 0.00415419, 0.00388095, 0.00557398, 0.00572308,\n",
      "       0.00179713, 0.00354074, 0.00330355, 0.0022461 , 0.0048592 ,\n",
      "       0.00748006, 0.0047749 , 0.00807797, 0.00169336, 0.00297313,\n",
      "       0.00483056, 0.00537351, 0.00464033, 0.00316635, 0.00511668,\n",
      "       0.00408743, 0.00346208, 0.00406822, 0.00456726, 0.00573966,\n",
      "       0.00489839, 0.00345684, 0.00418454, 0.00927696, 0.00781829,\n",
      "       0.00576198, 0.00684452, 0.0091054 , 0.00737369, 0.00529748,\n",
      "       0.00576416, 0.01099108, 0.00766915, 0.00628092, 0.00702074,\n",
      "       0.01127614, 0.00645582, 0.00715424, 0.00934114, 0.00737676,\n",
      "       0.00841975, 0.00533204, 0.00432845, 0.00731066, 0.0039342 ,\n",
      "       0.00514255, 0.00744084, 0.00785098, 0.00611247, 0.00732901,\n",
      "       0.00718947, 0.00256861, 0.00698871, 0.00353063, 0.00798019,\n",
      "       0.00251472, 0.00440227, 0.00352875, 0.00698716, 0.00229832,\n",
      "       0.00534498, 0.0068488 , 0.00552506, 0.00584598, 0.00457698,\n",
      "       0.00700389, 0.0055656 , 0.00529648, 0.00995385, 0.00465357,\n",
      "       0.00464994, 0.00674092, 0.00412831, 0.00623262, 0.00326675,\n",
      "       0.00706117, 0.00429041, 0.0044    , 0.00619609, 0.00754766,\n",
      "       0.00620288, 0.005382  , 0.00702882, 0.01145569, 0.00968214,\n",
      "       0.00759524, 0.00869577, 0.01015143, 0.00888776, 0.00650254,\n",
      "       0.00699144, 0.01107818, 0.00849572, 0.00657601, 0.00729178,\n",
      "       0.01158758, 0.00713428, 0.01329129, 0.00325278, 0.00869527,\n",
      "       0.01041098, 0.00626962, 0.00629171, 0.01008554, 0.00794214,\n",
      "       0.00841873, 0.00582839, 0.00516951, 0.01163614, 0.00745795,\n",
      "       0.00620744, 0.00455394, 0.0068396 , 0.00624412, 0.00611487,\n",
      "       0.00720413, 0.00437809, 0.00293765, 0.00540566, 0.00505085,\n",
      "       0.00459065, 0.00504885, 0.00375156, 0.0094841 , 0.00278629,\n",
      "       0.00762249, 0.00284077, 0.00449431, 0.0045056 , 0.00320188,\n",
      "       0.00343678, 0.00420513, 0.00300389, 0.0024671 , 0.0049747 ,\n",
      "       0.00693034, 0.00592616, 0.00593042, 0.00686282, 0.00803015,\n",
      "       0.00724847, 0.00613945, 0.00731105, 0.01165363, 0.0096611 ,\n",
      "       0.00744567, 0.00854355, 0.01015143, 0.00888776, 0.00668515,\n",
      "       0.00682341, 0.01066866, 0.00803712, 0.00657601, 0.00729178,\n",
      "       0.00764176, 0.0070801 , 0.01323175, 0.00482196, 0.00995229,\n",
      "       0.005398  , 0.00871904, 0.01046854, 0.00627841, 0.00774507,\n",
      "       0.00532811, 0.01515309, 0.00738059, 0.01006134, 0.00597403,\n",
      "       0.00774046, 0.00358609, 0.0082472 , 0.00685807, 0.00324896,\n",
      "       0.0036395 , 0.00887669, 0.00617713, 0.00647818, 0.00864973,\n",
      "       0.00843235, 0.00499224, 0.01428799, 0.00469984, 0.00341472,\n",
      "       0.00807852, 0.00584572, 0.01188984, 0.00699225, 0.00772568,\n",
      "       0.00533963, 0.004847  , 0.01024887, 0.00790773, 0.00601755]), 'std_score_time': array([2.33867428e-04, 1.16416938e-04, 2.33031368e-04, 1.19777185e-04,\n",
      "       2.12450085e-05, 2.89611750e-05, 3.81654456e-05, 2.30415422e-04,\n",
      "       1.00878437e-04, 4.48466805e-05, 6.88967817e-05, 1.28896819e-04,\n",
      "       1.79289503e-05, 2.05468683e-05, 1.58153307e-05, 1.07776105e-04,\n",
      "       2.65399184e-05, 4.95018064e-05, 1.09575892e-04, 3.62897827e-05,\n",
      "       3.13882745e-05, 7.22595386e-05, 3.55281764e-05, 3.57112513e-05,\n",
      "       6.24650489e-05, 3.99660660e-05, 2.94539499e-05, 6.25364979e-05,\n",
      "       3.83991608e-05, 4.03206915e-05, 3.66453622e-05, 5.55513038e-05,\n",
      "       3.39776506e-05, 4.32869925e-05, 4.19555465e-05, 3.12547025e-05,\n",
      "       4.89046198e-05, 5.19549917e-05, 3.73100015e-05, 5.45360807e-05,\n",
      "       4.52441329e-05, 7.56776174e-05, 6.73988028e-05, 9.78696390e-05,\n",
      "       4.11143145e-05, 9.29468768e-05, 1.37499647e-04, 3.65615027e-05,\n",
      "       5.50911825e-05, 7.95405830e-05, 6.16609632e-05, 9.94214508e-05,\n",
      "       5.57366549e-05, 2.55966080e-05, 1.02601463e-04, 5.33121429e-05,\n",
      "       5.38358654e-05, 3.86378180e-05, 6.08111159e-05, 2.20516436e-05,\n",
      "       1.33681193e-05, 2.20206890e-05, 2.46923390e-05, 2.59605319e-05,\n",
      "       2.62966074e-05, 4.25490002e-05, 2.83367277e-05, 2.54806894e-05,\n",
      "       1.10535605e-04, 1.99393208e-05, 1.63576692e-05, 1.10858230e-05,\n",
      "       6.43288496e-06, 7.54247264e-06, 1.03811797e-04, 3.70095679e-05,\n",
      "       1.72203585e-05, 2.58876470e-05, 2.01649693e-05, 2.14998044e-05,\n",
      "       2.23013023e-05, 1.03924249e-05, 1.11712271e-05, 5.24390811e-06,\n",
      "       4.98107939e-05, 1.82108100e-05, 1.08720963e-05, 1.36750047e-05,\n",
      "       2.65617558e-05, 4.53254726e-05, 1.16907791e-05, 1.11355515e-05,\n",
      "       5.55182632e-06, 1.58890556e-05, 3.13574003e-05, 5.41162909e-06,\n",
      "       1.53356346e-05, 1.12015128e-05, 2.44810259e-05, 3.79856992e-06,\n",
      "       9.58739183e-06, 1.77126873e-05, 1.90404367e-05, 2.46361045e-05,\n",
      "       8.41181834e-06, 2.19274592e-05, 3.53897347e-05, 1.46200170e-05,\n",
      "       6.40880494e-06, 7.46459596e-06, 1.45686043e-05, 5.48084022e-05,\n",
      "       2.22568053e-05, 7.17223956e-06, 2.43359860e-05, 1.98099299e-05,\n",
      "       2.25526333e-05, 2.55566034e-05, 2.24999442e-05, 7.69970208e-06,\n",
      "       1.77525648e-05, 8.32718520e-05, 2.57366644e-05, 2.19769689e-05,\n",
      "       2.06682370e-05, 2.24201713e-05, 9.80278624e-05, 5.76046128e-06,\n",
      "       6.28340393e-06, 1.01868467e-04, 1.24063829e-05, 2.15617939e-05,\n",
      "       2.03224394e-05, 1.32260222e-05, 1.81718130e-05, 2.10815958e-05,\n",
      "       1.02279781e-04, 6.27108849e-06, 2.17646783e-05, 1.71471862e-05,\n",
      "       6.08112281e-06, 2.08631379e-05, 5.66734553e-06, 2.79452612e-05,\n",
      "       9.17536795e-06, 1.30226314e-05, 3.66690565e-05, 1.59704147e-05,\n",
      "       2.43121494e-05, 2.44064245e-05, 3.57591627e-05, 2.43992500e-05,\n",
      "       1.88206364e-05, 2.22846773e-05, 2.72121570e-05, 1.92487532e-05,\n",
      "       3.40304753e-05, 2.12497171e-05, 4.34138171e-05, 2.78901235e-05,\n",
      "       1.20521948e-05, 2.44774034e-05, 1.12594168e-05, 1.92481626e-05,\n",
      "       2.88986136e-05, 2.48968366e-05, 1.94044017e-05, 5.66011933e-06,\n",
      "       1.11854655e-05, 1.97658061e-05, 6.69340788e-06, 2.96815715e-05,\n",
      "       1.19367495e-05, 1.07075162e-05, 1.76828809e-05, 6.35715322e-06,\n",
      "       2.40939168e-05, 2.35092809e-05, 1.82759932e-05, 6.69714351e-06,\n",
      "       9.03854864e-06, 2.46282584e-05, 8.75538468e-06, 2.34894485e-04,\n",
      "       1.40463957e-05, 1.18105297e-04, 2.19109658e-05, 1.67178863e-05,\n",
      "       2.32883089e-05, 8.71191536e-05, 1.89302550e-05, 4.98836396e-06,\n",
      "       3.18356571e-05, 2.48374035e-05, 3.40394273e-05, 1.03278415e-04,\n",
      "       2.47909468e-05, 1.84883731e-05, 7.15319313e-06, 2.15123857e-05,\n",
      "       1.97507309e-05, 3.27597886e-05, 6.03721792e-06, 1.35865960e-05,\n",
      "       7.46764137e-06, 6.66447100e-06, 1.65032507e-05, 1.94457210e-05,\n",
      "       4.59696741e-06, 8.38420214e-06, 4.42817183e-06, 1.35223485e-05,\n",
      "       7.21312942e-05, 2.45585487e-05, 8.09584682e-06, 1.30921110e-05,\n",
      "       8.55240377e-05, 1.01291190e-04, 2.03983780e-05, 7.09093891e-06,\n",
      "       5.03509333e-06, 6.00057458e-06, 2.37072003e-05, 2.13679451e-05,\n",
      "       8.27968376e-06, 2.55971410e-05, 5.98805717e-06, 3.40171097e-05,\n",
      "       1.22811259e-05, 1.66048913e-05, 2.41617675e-05, 4.20199878e-05,\n",
      "       2.54129602e-05, 7.03169108e-06, 1.50166613e-05, 1.58776034e-05,\n",
      "       4.58527960e-05, 2.40045717e-05, 7.93844367e-06, 9.83787979e-06,\n",
      "       7.79362584e-06, 1.21782847e-04, 1.90343455e-05, 1.04399028e-04,\n",
      "       9.87225669e-06, 9.59797040e-05, 8.52663508e-05, 6.22484566e-05,\n",
      "       9.18443823e-05, 9.98453515e-05, 1.24524506e-04, 1.67589098e-05,\n",
      "       2.17442973e-05, 2.07472938e-05, 1.71599112e-05, 2.10052045e-05,\n",
      "       4.42097740e-06, 2.53946119e-05, 2.22440318e-05, 2.28820236e-05,\n",
      "       2.49878140e-05, 1.29128700e-05, 7.14046728e-06, 8.45710727e-06,\n",
      "       1.41332153e-05, 3.22586593e-05, 1.58579723e-06, 1.67101321e-05,\n",
      "       7.51317434e-06, 9.47527147e-06, 1.71186532e-05, 2.90994149e-05,\n",
      "       2.36865709e-05, 2.31482709e-05, 1.60166187e-05, 1.10272137e-05,\n",
      "       9.46614840e-06, 4.21023179e-06, 6.87208210e-06, 2.67441465e-05,\n",
      "       1.60598585e-05, 6.25293349e-06, 5.90315928e-06, 2.12909794e-05,\n",
      "       8.13339395e-06, 2.57478820e-05, 1.10018227e-05, 2.98775677e-06,\n",
      "       7.18332666e-06, 3.89141193e-06, 8.94803700e-06, 1.82600617e-05,\n",
      "       1.66774435e-05, 9.10040187e-05, 8.35703884e-06, 4.57018006e-06,\n",
      "       2.68186885e-05, 1.76824952e-05, 2.16462012e-05, 1.54620285e-05]), 'split0_test_score': array([0.83283403, 0.83223487, 0.8286399 , 0.82684242, 0.83822648,\n",
      "       0.83702816, 0.83822648, 0.83582984, 0.83043739, 0.82983823,\n",
      "       0.836429  , 0.83403235, 0.83283403, 0.83163571, 0.836429  ,\n",
      "       0.83463152, 0.83523068, 0.83523068, 0.84062313, 0.83882564,\n",
      "       0.82025165, 0.83223487, 0.82744158, 0.81186339, 0.83103655,\n",
      "       0.83463152, 0.82923907, 0.836429  , 0.82504494, 0.836429  ,\n",
      "       0.83582984, 0.83762732, 0.83523068, 0.83343319, 0.84421809,\n",
      "       0.82264829, 0.82804074, 0.83822648, 0.8286399 , 0.83463152,\n",
      "       0.82384661, 0.83043739, 0.81066507, 0.82324745, 0.84122229,\n",
      "       0.82384661, 0.81665668, 0.83403235, 0.82444578, 0.83043739,\n",
      "       0.83523068, 0.82264829, 0.83163571, 0.82204913, 0.82144997,\n",
      "       0.82744158, 0.82324745, 0.82025165, 0.83463152, 0.81605752,\n",
      "       0.84661474, 0.84541642, 0.84242061, 0.84002397, 0.84122229,\n",
      "       0.84122229, 0.84242061, 0.84002397, 0.83582984, 0.83523068,\n",
      "       0.84182145, 0.83942481, 0.83762732, 0.836429  , 0.84182145,\n",
      "       0.83942481, 0.83762732, 0.83702816, 0.84242061, 0.84062313,\n",
      "       0.836429  , 0.83463152, 0.82684242, 0.83582984, 0.82504494,\n",
      "       0.84182145, 0.8256441 , 0.81845416, 0.83702816, 0.8256441 ,\n",
      "       0.82684242, 0.83163571, 0.81965249, 0.84242061, 0.82684242,\n",
      "       0.83463152, 0.83762732, 0.83043739, 0.81965249, 0.82684242,\n",
      "       0.82983823, 0.82744158, 0.83283403, 0.82504494, 0.82684242,\n",
      "       0.82744158, 0.82744158, 0.82264829, 0.82504494, 0.82444578,\n",
      "       0.836429  , 0.82744158, 0.83283403, 0.8286399 , 0.82444578,\n",
      "       0.82624326, 0.82324745, 0.82204913, 0.82144997, 0.82384661,\n",
      "       0.84421809, 0.84301977, 0.84002397, 0.83762732, 0.83942481,\n",
      "       0.83942481, 0.84182145, 0.83942481, 0.83523068, 0.83463152,\n",
      "       0.84122229, 0.83882564, 0.83582984, 0.83463152, 0.84002397,\n",
      "       0.83762732, 0.83523068, 0.83523068, 0.84062313, 0.83882564,\n",
      "       0.83523068, 0.83043739, 0.83283403, 0.82025165, 0.83043739,\n",
      "       0.82504494, 0.82684242, 0.84301977, 0.83822648, 0.83822648,\n",
      "       0.82324745, 0.83822648, 0.83822648, 0.82144997, 0.83043739,\n",
      "       0.82744158, 0.82923907, 0.8256441 , 0.83403235, 0.84062313,\n",
      "       0.83283403, 0.83043739, 0.83163571, 0.83403235, 0.82384661,\n",
      "       0.8256441 , 0.8256441 , 0.84182145, 0.82804074, 0.83403235,\n",
      "       0.83163571, 0.817855  , 0.83463152, 0.82085081, 0.82264829,\n",
      "       0.82085081, 0.81965249, 0.82324745, 0.84122229, 0.82923907,\n",
      "       0.84361893, 0.84122229, 0.83942481, 0.83702816, 0.83762732,\n",
      "       0.83762732, 0.83882564, 0.83523068, 0.83043739, 0.82983823,\n",
      "       0.836429  , 0.83403235, 0.83223487, 0.83103655, 0.83702816,\n",
      "       0.83403235, 0.83523068, 0.83523068, 0.84062313, 0.83882564,\n",
      "       0.82144997, 0.81905333, 0.84242061, 0.83582984, 0.83523068,\n",
      "       0.82025165, 0.83463152, 0.83403235, 0.83283403, 0.82144997,\n",
      "       0.82804074, 0.84481726, 0.84421809, 0.83582984, 0.83523068,\n",
      "       0.83582984, 0.83163571, 0.82684242, 0.83403235, 0.84481726,\n",
      "       0.81665668, 0.82085081, 0.83103655, 0.82025165, 0.82144997,\n",
      "       0.81845416, 0.82204913, 0.82923907, 0.82025165, 0.82384661,\n",
      "       0.82384661, 0.82204913, 0.82204913, 0.82684242, 0.83403235,\n",
      "       0.83103655, 0.83223487, 0.82624326, 0.82204913, 0.82504494,\n",
      "       0.83882564, 0.836429  , 0.83463152, 0.83223487, 0.83822648,\n",
      "       0.83702816, 0.83942481, 0.83582984, 0.83043739, 0.82983823,\n",
      "       0.836429  , 0.83403235, 0.83223487, 0.83103655, 0.836429  ,\n",
      "       0.83463152, 0.83523068, 0.83523068, 0.84062313, 0.83882564,\n",
      "       0.84002397, 0.83582984, 0.82624326, 0.83463152, 0.82804074,\n",
      "       0.82923907, 0.82624326, 0.82983823, 0.82384661, 0.83463152,\n",
      "       0.84062313, 0.82444578, 0.8286399 , 0.82504494, 0.82744158,\n",
      "       0.84601558, 0.82384661, 0.83463152, 0.83882564, 0.83103655,\n",
      "       0.82923907, 0.80647094, 0.82923907, 0.82025165, 0.81905333,\n",
      "       0.81845416, 0.82624326, 0.82144997, 0.82384661, 0.83163571,\n",
      "       0.82025165, 0.82983823, 0.81066507, 0.82144997, 0.82324745,\n",
      "       0.83582984, 0.83882564, 0.8256441 , 0.82204913, 0.82444578]), 'split0_train_score': array([0.88947211, 0.88467307, 0.87732454, 0.87192561, 0.88107379,\n",
      "       0.87657469, 0.87027594, 0.86577684, 0.87657469, 0.87402519,\n",
      "       0.86772645, 0.86367726, 0.87567487, 0.87312537, 0.86682663,\n",
      "       0.86277744, 0.87162567, 0.86802639, 0.8639772 , 0.86142771,\n",
      "       0.86502699, 0.86322735, 0.86262747, 0.86232753, 0.86007798,\n",
      "       0.85392921, 0.85122975, 0.86637672, 0.84613077, 0.85272945,\n",
      "       0.84643071, 0.85857828, 0.84868026, 0.84343131, 0.84763047,\n",
      "       0.84328134, 0.84808038, 0.85542891, 0.83563287, 0.84883023,\n",
      "       0.85017996, 0.84493101, 0.84838032, 0.84958008, 0.85227954,\n",
      "       0.84673065, 0.84253149, 0.84913017, 0.83158368, 0.8519796 ,\n",
      "       0.84928014, 0.83938212, 0.84013197, 0.8339832 , 0.83278344,\n",
      "       0.83728254, 0.83113377, 0.84103179, 0.8384823 , 0.83728254,\n",
      "       0.87867427, 0.87402519, 0.86682663, 0.86127774, 0.87537493,\n",
      "       0.87102579, 0.86472705, 0.86022795, 0.87282543, 0.87027594,\n",
      "       0.8639772 , 0.85992801, 0.87282543, 0.87027594, 0.8639772 ,\n",
      "       0.85992801, 0.86922615, 0.86592681, 0.86187762, 0.85932813,\n",
      "       0.84868026, 0.8474805 , 0.84943011, 0.84808038, 0.84208158,\n",
      "       0.84868026, 0.84373125, 0.84133173, 0.84088182, 0.83863227,\n",
      "       0.83533293, 0.83908218, 0.83758248, 0.84613077, 0.83653269,\n",
      "       0.84358128, 0.84718056, 0.83743251, 0.84073185, 0.83713257,\n",
      "       0.82933413, 0.83128374, 0.84133173, 0.83383323, 0.83068386,\n",
      "       0.83878224, 0.83368326, 0.83203359, 0.83218356, 0.83188362,\n",
      "       0.83533293, 0.83158368, 0.84013197, 0.83068386, 0.8354829 ,\n",
      "       0.83938212, 0.83053389, 0.83668266, 0.82618476, 0.83158368,\n",
      "       0.88137373, 0.87672466, 0.86952609, 0.8639772 , 0.87792442,\n",
      "       0.87357528, 0.86742651, 0.86292741, 0.87507499, 0.87252549,\n",
      "       0.86622675, 0.86217756, 0.87492501, 0.87237552, 0.86607678,\n",
      "       0.86202759, 0.87162567, 0.86802639, 0.8639772 , 0.86142771,\n",
      "       0.86022795, 0.85167966, 0.84763047, 0.85122975, 0.83893221,\n",
      "       0.84208158, 0.85392921, 0.85407918, 0.84628074, 0.84928014,\n",
      "       0.84313137, 0.85662867, 0.84658068, 0.84118176, 0.84178164,\n",
      "       0.84673065, 0.84088182, 0.84343131, 0.83683263, 0.84778044,\n",
      "       0.83593281, 0.83638272, 0.84328134, 0.84283143, 0.84118176,\n",
      "       0.83113377, 0.8339832 , 0.84733053, 0.83593281, 0.84403119,\n",
      "       0.84328134, 0.83008398, 0.84523095, 0.84028194, 0.83218356,\n",
      "       0.8309838 , 0.82873425, 0.83623275, 0.84253149, 0.83788242,\n",
      "       0.88572286, 0.88032394, 0.87387522, 0.86832633, 0.88032394,\n",
      "       0.87597481, 0.86967606, 0.86502699, 0.87657469, 0.87402519,\n",
      "       0.86772645, 0.86367726, 0.87567487, 0.87312537, 0.86682663,\n",
      "       0.86277744, 0.87162567, 0.86802639, 0.8639772 , 0.86142771,\n",
      "       0.85392921, 0.84328134, 0.85587882, 0.85407918, 0.85962807,\n",
      "       0.84928014, 0.85767846, 0.84673065, 0.84883023, 0.8489802 ,\n",
      "       0.85002999, 0.86262747, 0.85827834, 0.84703059, 0.84313137,\n",
      "       0.8489802 , 0.83968206, 0.83863227, 0.84058188, 0.85392921,\n",
      "       0.8369826 , 0.83818236, 0.83428314, 0.84043191, 0.8294841 ,\n",
      "       0.83788242, 0.83278344, 0.84268146, 0.83728254, 0.83173365,\n",
      "       0.83338332, 0.8339832 , 0.84373125, 0.83578284, 0.83983203,\n",
      "       0.83728254, 0.8339832 , 0.83578284, 0.82588482, 0.83488302,\n",
      "       0.88767247, 0.88242352, 0.87597481, 0.87042591, 0.88107379,\n",
      "       0.87657469, 0.87042591, 0.86577684, 0.87657469, 0.87402519,\n",
      "       0.86772645, 0.86367726, 0.87567487, 0.87312537, 0.86682663,\n",
      "       0.86277744, 0.87162567, 0.86802639, 0.8639772 , 0.86142771,\n",
      "       0.85737852, 0.86037792, 0.86067786, 0.85482903, 0.85332933,\n",
      "       0.84823035, 0.84553089, 0.85527894, 0.85107978, 0.85317936,\n",
      "       0.85707858, 0.84553089, 0.84718056, 0.83983203, 0.84508098,\n",
      "       0.8474805 , 0.84253149, 0.84913017, 0.84388122, 0.84253149,\n",
      "       0.8384823 , 0.83608278, 0.8429814 , 0.83938212, 0.84013197,\n",
      "       0.84238152, 0.8354829 , 0.8429814 , 0.83638272, 0.84133173,\n",
      "       0.83608278, 0.84568086, 0.83503299, 0.83443311, 0.83068386,\n",
      "       0.84418116, 0.83608278, 0.83083383, 0.84088182, 0.83203359]), 'std_train_score': array([0.00135586, 0.00234218, 0.00143389, 0.00192199, 0.00104137,\n",
      "       0.00113198, 0.00108298, 0.0010808 , 0.00159834, 0.00164765,\n",
      "       0.00149672, 0.00151747, 0.0030314 , 0.00328166, 0.00295081,\n",
      "       0.0024468 , 0.00241024, 0.00327688, 0.00291552, 0.00290377,\n",
      "       0.00172692, 0.00404141, 0.00168653, 0.00299773, 0.00452237,\n",
      "       0.00304182, 0.00277779, 0.00847063, 0.00244194, 0.0025643 ,\n",
      "       0.00607103, 0.00586986, 0.00215297, 0.00387726, 0.00583279,\n",
      "       0.00700833, 0.00509563, 0.00418549, 0.00862952, 0.00548862,\n",
      "       0.00215811, 0.00578736, 0.00089063, 0.0039078 , 0.0048017 ,\n",
      "       0.00442632, 0.00616882, 0.00542816, 0.00371211, 0.00564368,\n",
      "       0.0056537 , 0.00422301, 0.00355582, 0.00424976, 0.00485193,\n",
      "       0.00246664, 0.00404253, 0.00471566, 0.00450283, 0.00408725,\n",
      "       0.0011573 , 0.00204441, 0.00139984, 0.00194556, 0.0013989 ,\n",
      "       0.00212292, 0.00222548, 0.00196852, 0.00167282, 0.00239557,\n",
      "       0.00226713, 0.00208132, 0.00252359, 0.0029924 , 0.00276069,\n",
      "       0.00234798, 0.0018871 , 0.00272236, 0.00253815, 0.00232019,\n",
      "       0.00123365, 0.00272985, 0.0046172 , 0.00074387, 0.00285419,\n",
      "       0.00285766, 0.00299897, 0.00328765, 0.0050209 , 0.00568774,\n",
      "       0.00379284, 0.00163599, 0.00450792, 0.00347817, 0.00124367,\n",
      "       0.00415881, 0.00450025, 0.00518042, 0.00248316, 0.00123917,\n",
      "       0.00312564, 0.0022092 , 0.00452685, 0.00553005, 0.0033201 ,\n",
      "       0.00364804, 0.00361116, 0.00221736, 0.00267859, 0.00326028,\n",
      "       0.00175894, 0.00144542, 0.00428816, 0.00247449, 0.00214978,\n",
      "       0.00540056, 0.00371469, 0.0024561 , 0.00283287, 0.00221935,\n",
      "       0.00085899, 0.00161067, 0.0012783 , 0.00226082, 0.0009917 ,\n",
      "       0.00162949, 0.00185856, 0.00178532, 0.00167464, 0.00204436,\n",
      "       0.00211235, 0.00207619, 0.00306843, 0.00328718, 0.00310382,\n",
      "       0.00254948, 0.00258007, 0.00329126, 0.00297149, 0.00292451,\n",
      "       0.00605218, 0.00289744, 0.00228977, 0.00459158, 0.00848203,\n",
      "       0.00405238, 0.0053782 , 0.0029764 , 0.00548943, 0.00429033,\n",
      "       0.00223552, 0.0060705 , 0.00254206, 0.00286658, 0.00598013,\n",
      "       0.00393592, 0.0076411 , 0.00432657, 0.00489393, 0.00273333,\n",
      "       0.00202454, 0.00284874, 0.00553734, 0.00307244, 0.00342987,\n",
      "       0.00175751, 0.00413966, 0.00563253, 0.00418029, 0.00378811,\n",
      "       0.00416747, 0.00300799, 0.00600513, 0.00535269, 0.00465829,\n",
      "       0.00508418, 0.00362373, 0.00196534, 0.00499199, 0.00333697,\n",
      "       0.00102336, 0.0017013 , 0.00122705, 0.00193122, 0.00131315,\n",
      "       0.00146742, 0.0014422 , 0.00111077, 0.00158573, 0.00196772,\n",
      "       0.0018702 , 0.0018633 , 0.0030613 , 0.00329753, 0.00296389,\n",
      "       0.00243133, 0.00256999, 0.00327688, 0.00291552, 0.00290377,\n",
      "       0.00577041, 0.00587572, 0.00368028, 0.00268417, 0.00664912,\n",
      "       0.00220191, 0.0058663 , 0.00440901, 0.00527673, 0.00423222,\n",
      "       0.00368653, 0.00706085, 0.0049885 , 0.0028866 , 0.00359414,\n",
      "       0.0030663 , 0.00279547, 0.00589279, 0.00316412, 0.00682405,\n",
      "       0.00130188, 0.00438099, 0.00411736, 0.00181205, 0.00364505,\n",
      "       0.00253458, 0.00173528, 0.00348344, 0.00518053, 0.00179751,\n",
      "       0.00388076, 0.00173082, 0.00616471, 0.00187827, 0.00272205,\n",
      "       0.00170441, 0.00495949, 0.002386  , 0.00716374, 0.00194321,\n",
      "       0.00164868, 0.00220158, 0.00187921, 0.00210656, 0.00131845,\n",
      "       0.00151768, 0.00152184, 0.00114751, 0.00150946, 0.00172878,\n",
      "       0.00160584, 0.00163401, 0.00304006, 0.00328166, 0.00295081,\n",
      "       0.0024468 , 0.00241024, 0.00323692, 0.00291552, 0.00290377,\n",
      "       0.00681782, 0.00491345, 0.00442108, 0.00339033, 0.00142986,\n",
      "       0.00385354, 0.00518436, 0.00809599, 0.00453425, 0.00312221,\n",
      "       0.00550881, 0.00414229, 0.0037998 , 0.00406577, 0.00353417,\n",
      "       0.00175881, 0.0058476 , 0.00456135, 0.00556579, 0.00457781,\n",
      "       0.00322151, 0.00322993, 0.00281868, 0.00181247, 0.00285362,\n",
      "       0.00502313, 0.00198531, 0.00352991, 0.00398749, 0.00407561,\n",
      "       0.00441348, 0.00537955, 0.00515542, 0.00347406, 0.00272333,\n",
      "       0.00459692, 0.00377818, 0.00468609, 0.00554724, 0.00320253]), 'param_min_samples_leaf': masked_array(data=[5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13,\n",
      "                   13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11,\n",
      "                   11, 11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9,\n",
      "                   9, 9, 11, 11, 11, 11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7,\n",
      "                   7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13, 13, 13, 13, 5, 5,\n",
      "                   5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13, 13,\n",
      "                   13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11,\n",
      "                   11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9,\n",
      "                   11, 11, 11, 11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7,\n",
      "                   9, 9, 9, 9, 11, 11, 11, 11, 13, 13, 13, 13, 5, 5, 5, 5,\n",
      "                   7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13, 13, 13, 13,\n",
      "                   5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13,\n",
      "                   13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11,\n",
      "                   11, 11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9,\n",
      "                   9, 9, 11, 11, 11, 11, 13, 13, 13, 13, 5, 5, 5, 5, 7, 7,\n",
      "                   7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13, 13, 13, 13, 5, 5,\n",
      "                   5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11, 11, 13, 13,\n",
      "                   13, 13, 5, 5, 5, 5, 7, 7, 7, 7, 9, 9, 9, 9, 11, 11, 11,\n",
      "                   11, 13, 13, 13, 13],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator')\n",
    "print(dt_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(dt_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(dt_clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(dt_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8481468154012235\n",
    "{'max_depth': 20, 'min_samples_split': 100, 'max_features': None, 'min_samples_leaf': 9}\n",
    "699\n",
    "<function _passthrough_scorer at 0x2ba712f58950>\n",
    "5\n",
    "0.30017995834350586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "#RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "\n",
    "#max_depth \n",
    "#min_samples_leaf \n",
    "#min_weight_fraction_leaf \n",
    "#max_features \n",
    "#max_leaf_nodes \n",
    "#min_impurity_decrease \n",
    "#min_impurity_split \n",
    "#oob_score\n",
    "#warm_start \n",
    "#class_weight\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [30, 70, 100, 150], \n",
    "    'max_depth': [None] + [*range(65, 120, 15)], \n",
    "    'min_samples_split': [25, 30, 40, 45, 50, 100],\n",
    "    #'min_samples_leaf': [*range(5, 14, 2)],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "          \n",
    "rf = RandomForestClassifier(criterion='gini')\n",
    "rf_clf = GridSearchCV(rf, params, cv=5)\n",
    "rf_clf = rf_clf.fit(X, y)\n",
    "\n",
    "opt_results['RandomForest'] = rf_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Estimator\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=40,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "Best Score\n",
    "0.860501379393067\n",
    "Best Params\n",
    "{'bootstrap': False, 'max_features': 'auto', 'max_depth': 80, 'n_estimators': 30, 'min_samples_split': 40, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator')\n",
    "print(rf_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(rf_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(rf_clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(rf_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "    'C': [0.025, 0.25, 0.5, 1, 2, 3],\n",
    "    'gamma': ['auto', 2, 3]\n",
    "}\n",
    "          \n",
    "svc = SVC()\n",
    "svc_clf = GridSearchCV(svc, params, cv=5)\n",
    "svc_clf = svc_clf.fit(X, y)\n",
    "\n",
    "opt_results['SVC'] = svc_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Best Score\n",
      "0.863260165527168\n",
      "Best Params\n",
      "{'C': 1, 'kernel': 'linear', 'gamma': 'auto'}\n",
      "cv_results_\n",
      "{'params': [{'C': 0.025, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 0.025, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 0.025, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 0.025, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 0.025, 'kernel': 'linear', 'gamma': 2}, {'C': 0.025, 'kernel': 'poly', 'gamma': 2}, {'C': 0.025, 'kernel': 'rbf', 'gamma': 2}, {'C': 0.025, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 0.025, 'kernel': 'linear', 'gamma': 3}, {'C': 0.025, 'kernel': 'poly', 'gamma': 3}, {'C': 0.025, 'kernel': 'rbf', 'gamma': 3}, {'C': 0.025, 'kernel': 'sigmoid', 'gamma': 3}, {'C': 0.25, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 0.25, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 0.25, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 0.25, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 0.25, 'kernel': 'linear', 'gamma': 2}, {'C': 0.25, 'kernel': 'poly', 'gamma': 2}, {'C': 0.25, 'kernel': 'rbf', 'gamma': 2}, {'C': 0.25, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 0.25, 'kernel': 'linear', 'gamma': 3}, {'C': 0.25, 'kernel': 'poly', 'gamma': 3}, {'C': 0.25, 'kernel': 'rbf', 'gamma': 3}, {'C': 0.25, 'kernel': 'sigmoid', 'gamma': 3}, {'C': 0.5, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 0.5, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 0.5, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 0.5, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 0.5, 'kernel': 'linear', 'gamma': 2}, {'C': 0.5, 'kernel': 'poly', 'gamma': 2}, {'C': 0.5, 'kernel': 'rbf', 'gamma': 2}, {'C': 0.5, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 0.5, 'kernel': 'linear', 'gamma': 3}, {'C': 0.5, 'kernel': 'poly', 'gamma': 3}, {'C': 0.5, 'kernel': 'rbf', 'gamma': 3}, {'C': 0.5, 'kernel': 'sigmoid', 'gamma': 3}, {'C': 1, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 1, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 1, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 1, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 1, 'kernel': 'linear', 'gamma': 2}, {'C': 1, 'kernel': 'poly', 'gamma': 2}, {'C': 1, 'kernel': 'rbf', 'gamma': 2}, {'C': 1, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 1, 'kernel': 'linear', 'gamma': 3}, {'C': 1, 'kernel': 'poly', 'gamma': 3}, {'C': 1, 'kernel': 'rbf', 'gamma': 3}, {'C': 1, 'kernel': 'sigmoid', 'gamma': 3}, {'C': 2, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 2, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 2, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 2, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 2, 'kernel': 'linear', 'gamma': 2}, {'C': 2, 'kernel': 'poly', 'gamma': 2}, {'C': 2, 'kernel': 'rbf', 'gamma': 2}, {'C': 2, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 2, 'kernel': 'linear', 'gamma': 3}, {'C': 2, 'kernel': 'poly', 'gamma': 3}, {'C': 2, 'kernel': 'rbf', 'gamma': 3}, {'C': 2, 'kernel': 'sigmoid', 'gamma': 3}, {'C': 3, 'kernel': 'linear', 'gamma': 'auto'}, {'C': 3, 'kernel': 'poly', 'gamma': 'auto'}, {'C': 3, 'kernel': 'rbf', 'gamma': 'auto'}, {'C': 3, 'kernel': 'sigmoid', 'gamma': 'auto'}, {'C': 3, 'kernel': 'linear', 'gamma': 2}, {'C': 3, 'kernel': 'poly', 'gamma': 2}, {'C': 3, 'kernel': 'rbf', 'gamma': 2}, {'C': 3, 'kernel': 'sigmoid', 'gamma': 2}, {'C': 3, 'kernel': 'linear', 'gamma': 3}, {'C': 3, 'kernel': 'poly', 'gamma': 3}, {'C': 3, 'kernel': 'rbf', 'gamma': 3}, {'C': 3, 'kernel': 'sigmoid', 'gamma': 3}], 'std_fit_time': array([0.04423411, 0.00640434, 0.41062645, 0.00971507, 0.04339775,\n",
      "       0.24980241, 0.12546879, 0.10782201, 0.04299506, 0.12911198,\n",
      "       0.03344519, 0.0696219 , 0.02772928, 0.00838485, 0.01323188,\n",
      "       0.01442928, 0.02833491, 0.78576774, 0.1756461 , 0.07765454,\n",
      "       0.1198645 , 0.5648258 , 0.06714456, 0.06429015, 0.04975126,\n",
      "       0.00825136, 0.01987402, 0.08912551, 0.13383395, 0.91468594,\n",
      "       0.29628879, 0.16162437, 0.04635672, 0.22536709, 0.01571868,\n",
      "       0.06308238, 0.06444018, 0.00883723, 0.07497094, 0.03774528,\n",
      "       0.06664071, 0.51375467, 0.16908385, 0.11347383, 0.09179906,\n",
      "       0.64158761, 0.08273604, 0.0613604 , 0.12513549, 0.00494444,\n",
      "       0.08199287, 0.02514507, 0.12218256, 0.3734629 , 0.03015923,\n",
      "       0.10777342, 0.08957638, 0.36544637, 0.30093121, 0.0616166 ,\n",
      "       0.14109554, 0.01343179, 0.06889947, 0.11683393, 0.1867723 ,\n",
      "       0.19215422, 0.1390517 , 0.10721313, 0.04436371, 0.25333267,\n",
      "       0.20233983, 0.07126424]), 'split1_test_score': array([0.82434053, 0.82434053, 0.82434053, 0.82434053, 0.82434053,\n",
      "       0.81594724, 0.82434053, 0.75239808, 0.82434053, 0.80695444,\n",
      "       0.82434053, 0.79376499, 0.84892086, 0.82434053, 0.82434053,\n",
      "       0.82434053, 0.84892086, 0.80995204, 0.82434053, 0.76019185,\n",
      "       0.84892086, 0.80935252, 0.82434053, 0.76678657, 0.85971223,\n",
      "       0.82434053, 0.82434053, 0.82434053, 0.85971223, 0.808753  ,\n",
      "       0.82434053, 0.76019185, 0.85971223, 0.80515588, 0.82434053,\n",
      "       0.76199041, 0.85911271, 0.82434053, 0.82434053, 0.82434053,\n",
      "       0.85911271, 0.80755396, 0.82494005, 0.74460432, 0.85911271,\n",
      "       0.80515588, 0.82494005, 0.74640288, 0.85911271, 0.82434053,\n",
      "       0.82434053, 0.82434053, 0.85911271, 0.80515588, 0.82613909,\n",
      "       0.73441247, 0.85911271, 0.8057554 , 0.82553957, 0.74820144,\n",
      "       0.85191847, 0.82434053, 0.82434053, 0.82434053, 0.85191847,\n",
      "       0.80515588, 0.82613909, 0.73321343, 0.85191847, 0.80515588,\n",
      "       0.82553957, 0.7440048 ]), 'param_gamma': masked_array(data=['auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   'auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   'auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   'auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   'auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   'auto', 'auto', 'auto', 'auto', 2, 2, 2, 2, 3, 3, 3, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split3_train_score': array([0.82473763, 0.82473763, 0.82473763, 0.82473763, 0.82473763,\n",
      "       0.97346327, 0.82473763, 0.79565217, 0.82473763, 0.98365817,\n",
      "       0.82473763, 0.79850075, 0.85817091, 0.82473763, 0.82473763,\n",
      "       0.82473763, 0.85817091, 0.99505247, 0.82473763, 0.74392804,\n",
      "       0.85817091, 0.99895052, 0.82473763, 0.77406297, 0.88155922,\n",
      "       0.82473763, 0.82473763, 0.82473763, 0.88155922, 0.99805097,\n",
      "       0.82668666, 0.76686657, 0.88155922, 0.99895052, 0.82668666,\n",
      "       0.75967016, 0.905997  , 0.82473763, 0.82473763, 0.82473763,\n",
      "       0.905997  , 0.99895052, 0.99175412, 0.75817091, 0.905997  ,\n",
      "       0.99910045, 0.9976012 , 0.75292354, 0.92638681, 0.82473763,\n",
      "       0.82473763, 0.82473763, 0.92638681, 0.99910045, 0.99925037,\n",
      "       0.75442279, 0.92638681, 0.99925037, 0.99925037, 0.74872564,\n",
      "       0.93388306, 0.82473763, 0.82473763, 0.82473763, 0.93388306,\n",
      "       0.99910045, 0.99925037, 0.75232384, 0.93388306, 0.99925037,\n",
      "       0.99925037, 0.74797601]), 'split2_train_score': array([0.82473763, 0.82473763, 0.82473763, 0.82473763, 0.82473763,\n",
      "       0.97391304, 0.82473763, 0.8       , 0.82473763, 0.98155922,\n",
      "       0.82473763, 0.74662669, 0.85562219, 0.82473763, 0.82473763,\n",
      "       0.82473763, 0.85562219, 0.994003  , 0.82473763, 0.74857571,\n",
      "       0.85562219, 0.9988006 , 0.82473763, 0.74632684, 0.88710645,\n",
      "       0.82473763, 0.82473763, 0.82473763, 0.88710645, 0.9976012 ,\n",
      "       0.82578711, 0.74437781, 0.88710645, 0.99895052, 0.82548726,\n",
      "       0.74527736, 0.90404798, 0.82473763, 0.82473763, 0.82473763,\n",
      "       0.90404798, 0.99895052, 0.99055472, 0.74017991, 0.90404798,\n",
      "       0.99910045, 0.99775112, 0.75232384, 0.92383808, 0.82473763,\n",
      "       0.82473763, 0.82473763, 0.92383808, 0.99895052, 0.99895052,\n",
      "       0.73928036, 0.92383808, 0.99910045, 0.99895052, 0.75292354,\n",
      "       0.93238381, 0.82473763, 0.82473763, 0.82473763, 0.93238381,\n",
      "       0.99895052, 0.99895052, 0.73808096, 0.93238381, 0.99910045,\n",
      "       0.99895052, 0.74407796]), 'mean_fit_time': array([2.16411967, 1.27019992, 1.83259254, 1.45056853, 2.16371884,\n",
      "       6.94664345, 6.23605533, 1.89348025, 2.1600183 , 7.37631335,\n",
      "       6.59196463, 1.72329187, 2.22129545, 1.26982412, 1.87807236,\n",
      "       1.53126707, 2.2186028 , 7.11801538, 7.34079113, 1.68324327,\n",
      "       2.30876269, 6.43226333, 7.45387049, 1.58390684, 2.2686233 ,\n",
      "       1.26425829, 2.01123891, 1.72853465, 2.34206939, 6.28136902,\n",
      "       7.44124179, 1.7344337 , 2.27349882, 6.24868512, 7.49650373,\n",
      "       1.5651978 , 2.38482904, 1.26266117, 2.29606833, 2.02722621,\n",
      "       2.38634911, 5.94336648, 7.5173728 , 1.75371242, 2.40269718,\n",
      "       6.46857433, 7.61709118, 1.542735  , 2.71410823, 1.2605875 ,\n",
      "       2.33183327, 2.20999837, 2.71454544, 6.12709532, 7.99543729,\n",
      "       1.61566586, 2.75074129, 6.06863198, 8.51451159, 1.55508852,\n",
      "       3.04906974, 1.27041426, 2.47606993, 2.41292152, 3.07260246,\n",
      "       5.89722757, 8.06631498, 1.6188839 , 3.14837532, 6.03942847,\n",
      "       8.40457711, 1.5239574 ]), 'split2_test_score': array([0.82483503, 0.82483503, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.83023395, 0.82483503, 0.80563887, 0.82483503, 0.83023395,\n",
      "       0.82483503, 0.76064787, 0.84703059, 0.82483503, 0.82483503,\n",
      "       0.82483503, 0.84703059, 0.82903419, 0.82483503, 0.75704859,\n",
      "       0.84703059, 0.82303539, 0.82483503, 0.75764847, 0.85902819,\n",
      "       0.82483503, 0.82483503, 0.82483503, 0.85902819, 0.82483503,\n",
      "       0.82423515, 0.74985003, 0.85902819, 0.81763647, 0.82423515,\n",
      "       0.75644871, 0.86142771, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.86142771, 0.82123575, 0.82843431, 0.74445111, 0.86142771,\n",
      "       0.81583683, 0.82783443, 0.76064787, 0.85842831, 0.82483503,\n",
      "       0.82483503, 0.82483503, 0.85842831, 0.81703659, 0.82783443,\n",
      "       0.74265147, 0.85842831, 0.81583683, 0.82843431, 0.76484703,\n",
      "       0.85482903, 0.82483503, 0.82483503, 0.82483503, 0.85482903,\n",
      "       0.81583683, 0.82783443, 0.74145171, 0.85482903, 0.81583683,\n",
      "       0.82843431, 0.75644871]), 'mean_score_time': array([0.35211797, 0.30288396, 0.38448124, 0.3392498 , 0.35251698,\n",
      "       0.52188139, 0.90921068, 0.35614185, 0.35105476, 0.50287852,\n",
      "       0.94960246, 0.34832239, 0.34940219, 0.30164714, 0.41224933,\n",
      "       0.34950795, 0.34870577, 0.4926712 , 0.91962509, 0.31450405,\n",
      "       0.35982656, 0.49303164, 0.96957312, 0.31588345, 0.34188437,\n",
      "       0.30170727, 0.42220621, 0.36933646, 0.34617772, 0.49943018,\n",
      "       0.92768531, 0.30399613, 0.33834357, 0.4768621 , 0.95698476,\n",
      "       0.31108589, 0.32357926, 0.29960632, 0.43084531, 0.38016758,\n",
      "       0.32203193, 0.47711458, 0.91907616, 0.30774727, 0.32210298,\n",
      "       0.4768806 , 0.95585771, 0.30856166, 0.30754991, 0.29913697,\n",
      "       0.43604579, 0.3865962 , 0.30761294, 0.47707272, 0.9257349 ,\n",
      "       0.30727468, 0.30742068, 0.47496114, 0.95883679, 0.3051908 ,\n",
      "       0.29822755, 0.30879788, 0.43739357, 0.42037206, 0.29756031,\n",
      "       0.47474241, 0.9248837 , 0.29893489, 0.30477815, 0.47354479,\n",
      "       0.98044238, 0.3030571 ]), 'mean_test_score': array([0.82475711, 0.82475711, 0.82475711, 0.82475711, 0.82475711,\n",
      "       0.83075447, 0.82475711, 0.78517452, 0.82475711, 0.82643637,\n",
      "       0.82475711, 0.79465035, 0.84466835, 0.82475711, 0.82475711,\n",
      "       0.82475711, 0.84466835, 0.82571668, 0.82475711, 0.75038983,\n",
      "       0.84466835, 0.82247811, 0.82475711, 0.76274439, 0.8575027 ,\n",
      "       0.82475711, 0.82475711, 0.82475711, 0.8575027 , 0.82307785,\n",
      "       0.82463716, 0.75458798, 0.8575027 , 0.82043901, 0.82463716,\n",
      "       0.75770661, 0.86326017, 0.82475711, 0.82475711, 0.82475711,\n",
      "       0.86326017, 0.82175843, 0.82655632, 0.74679141, 0.86326017,\n",
      "       0.8206789 , 0.82619647, 0.75230898, 0.86326017, 0.82475711,\n",
      "       0.82475711, 0.82475711, 0.86326017, 0.82055895, 0.82655632,\n",
      "       0.74199352, 0.86326017, 0.82055895, 0.82667626, 0.7518292 ,\n",
      "       0.86038143, 0.82475711, 0.82475711, 0.82475711, 0.86038143,\n",
      "       0.82043901, 0.82655632, 0.74139379, 0.86038143, 0.8206789 ,\n",
      "       0.82655632, 0.74871057]), 'rank_test_score': array([25, 25, 25, 25, 25, 16, 25, 62, 25, 22, 25, 61, 13, 25, 25, 25, 13,\n",
      "       24, 25, 68, 13, 53, 25, 63, 10, 25, 25, 25, 10, 52, 50, 65, 10, 59,\n",
      "       50, 64,  1, 25, 25, 25,  1, 54, 18, 70,  1, 55, 23, 66,  1, 25, 25,\n",
      "       25,  1, 57, 18, 71,  1, 57, 17, 67,  7, 25, 25, 25,  7, 59, 18, 72,\n",
      "        7, 55, 18, 69], dtype=int32), 'mean_train_score': array([0.82475712, 0.82475712, 0.82475712, 0.82475712, 0.82475712,\n",
      "       0.97247211, 0.82475712, 0.7776466 , 0.82475712, 0.98197794,\n",
      "       0.82475712, 0.78733297, 0.85621346, 0.82475712, 0.82475712,\n",
      "       0.82475712, 0.85621346, 0.9942725 , 0.82475712, 0.7467314 ,\n",
      "       0.85621346, 0.99862058, 0.82475712, 0.75881697, 0.88347154,\n",
      "       0.82475712, 0.82475712, 0.82475712, 0.88347154, 0.99739114,\n",
      "       0.82643645, 0.74808076, 0.88347154, 0.99877052, 0.82640648,\n",
      "       0.75362915, 0.90605144, 0.82475712, 0.82475712, 0.82475712,\n",
      "       0.90605144, 0.99868055, 0.99031423, 0.74235381, 0.90605144,\n",
      "       0.99898043, 0.99730116, 0.75000022, 0.9237434 , 0.82475712,\n",
      "       0.82475712, 0.82475712, 0.9237434 , 0.9988305 , 0.99898043,\n",
      "       0.7368365 , 0.9237434 , 0.99910038, 0.99901041, 0.74781101,\n",
      "       0.93142   , 0.82475712, 0.82475712, 0.82475712, 0.93142   ,\n",
      "       0.99886048, 0.99898043, 0.73731645, 0.93142   , 0.99910038,\n",
      "       0.99907039, 0.7454721 ]), 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
      "                   'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
      "                   'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
      "                   'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
      "                   'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
      "                   'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
      "                   'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split1_train_score': array([0.8248613 , 0.8248613 , 0.8248613 , 0.8248613 , 0.8248613 ,\n",
      "       0.97180987, 0.8248613 , 0.74748838, 0.8248613 , 0.98140651,\n",
      "       0.8248613 , 0.79442195, 0.85545059, 0.8248613 , 0.8248613 ,\n",
      "       0.8248613 , 0.85545059, 0.9937022 , 0.8248613 , 0.75498575,\n",
      "       0.85545059, 0.99835058, 0.8248613 , 0.78032689, 0.8854401 ,\n",
      "       0.8248613 , 0.8248613 , 0.8248613 , 0.8854401 , 0.99700105,\n",
      "       0.82711051, 0.7491378 , 0.8854401 , 0.99865047, 0.82696056,\n",
      "       0.77133003, 0.90793222, 0.8248613 , 0.8248613 , 0.8248613 ,\n",
      "       0.90793222, 0.99835058, 0.99055331, 0.7402909 , 0.90793222,\n",
      "       0.99880042, 0.99700105, 0.76203329, 0.92472635, 0.8248613 ,\n",
      "       0.8248613 , 0.8248613 , 0.92472635, 0.99865047, 0.99880042,\n",
      "       0.73354326, 0.92472635, 0.99895037, 0.99880042, 0.75978408,\n",
      "       0.93147398, 0.8248613 , 0.8248613 , 0.8248613 , 0.93147398,\n",
      "       0.99865047, 0.99880042, 0.73699205, 0.93147398, 0.99895037,\n",
      "       0.99895037, 0.7582846 ]), 'split4_test_score': array([0.82533013, 0.82533013, 0.82533013, 0.82533013, 0.82533013,\n",
      "       0.83733493, 0.82533013, 0.78031212, 0.82533013, 0.83253301,\n",
      "       0.82533013, 0.81392557, 0.84633854, 0.82533013, 0.82533013,\n",
      "       0.82533013, 0.84633854, 0.82953181, 0.82533013, 0.74969988,\n",
      "       0.84633854, 0.82713085, 0.82533013, 0.74129652, 0.86494598,\n",
      "       0.82533013, 0.82533013, 0.82533013, 0.86494598, 0.82953181,\n",
      "       0.82533013, 0.7454982 , 0.86494598, 0.82352941, 0.82533013,\n",
      "       0.74189676, 0.8817527 , 0.82533013, 0.82533013, 0.82533013,\n",
      "       0.8817527 , 0.82653061, 0.82833133, 0.73589436, 0.8817527 ,\n",
      "       0.82472989, 0.82833133, 0.742497  , 0.8757503 , 0.82533013,\n",
      "       0.82533013, 0.82533013, 0.8757503 , 0.82352941, 0.82953181,\n",
      "       0.73589436, 0.8757503 , 0.82352941, 0.82833133, 0.742497  ,\n",
      "       0.8757503 , 0.82533013, 0.82533013, 0.82533013, 0.8757503 ,\n",
      "       0.82472989, 0.82953181, 0.73529412, 0.8757503 , 0.82412965,\n",
      "       0.82773109, 0.74189676]), 'split4_train_score': array([0.824614  , 0.824614  , 0.824614  , 0.824614  , 0.824614  ,\n",
      "       0.97106881, 0.824614  , 0.77454654, 0.824614  , 0.98126218,\n",
      "       0.824614  , 0.81142258, 0.85339529, 0.824614  , 0.824614  ,\n",
      "       0.824614  , 0.85339529, 0.9943037 , 0.824614  , 0.74501574,\n",
      "       0.85339529, 0.99865088, 0.824614  , 0.74036876, 0.87872883,\n",
      "       0.824614  , 0.824614  , 0.824614  , 0.87872883, 0.99700195,\n",
      "       0.82551342, 0.73856993, 0.87872883, 0.99880078, 0.82551342,\n",
      "       0.74096837, 0.90571129, 0.824614  , 0.824614  , 0.824614  ,\n",
      "       0.90571129, 0.99880078, 0.98950682, 0.72897617, 0.90571129,\n",
      "       0.99910058, 0.99715185, 0.74006896, 0.92324989, 0.824614  ,\n",
      "       0.824614  , 0.824614  , 0.92324989, 0.99880078, 0.99910058,\n",
      "       0.71668416, 0.92324989, 0.99925049, 0.99925049, 0.73931944,\n",
      "       0.93104482, 0.824614  , 0.824614  , 0.824614  , 0.93104482,\n",
      "       0.99895068, 0.99910058, 0.71728377, 0.93104482, 0.99925049,\n",
      "       0.99925049, 0.73931944]), 'param_C': masked_array(data=[0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
      "                   0.025, 0.025, 0.025, 0.025, 0.25, 0.25, 0.25, 0.25,\n",
      "                   0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'split3_test_score': array([0.82483503, 0.82483503, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.82543491, 0.82483503, 0.82063587, 0.82483503, 0.82903419,\n",
      "       0.82483503, 0.81823635, 0.83803239, 0.82483503, 0.82483503,\n",
      "       0.82483503, 0.83803239, 0.83023395, 0.82483503, 0.74745051,\n",
      "       0.83803239, 0.82663467, 0.82483503, 0.80203959, 0.85182963,\n",
      "       0.82483503, 0.82483503, 0.82483503, 0.85182963, 0.82723455,\n",
      "       0.82483503, 0.78884223, 0.85182963, 0.82783443, 0.82483503,\n",
      "       0.78044391, 0.86262747, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.86262747, 0.82663467, 0.82603479, 0.77804439, 0.86262747,\n",
      "       0.82783443, 0.82603479, 0.77384523, 0.86442711, 0.82483503,\n",
      "       0.82483503, 0.82483503, 0.86442711, 0.82843431, 0.82603479,\n",
      "       0.76904619, 0.86442711, 0.82843431, 0.82663467, 0.76844631,\n",
      "       0.86382723, 0.82483503, 0.82483503, 0.82483503, 0.86382723,\n",
      "       0.82783443, 0.82603479, 0.76784643, 0.86382723, 0.82963407,\n",
      "       0.82663467, 0.76664667]), 'std_test_score': array([0.00034953, 0.00034953, 0.00034953, 0.00034953, 0.00034953,\n",
      "       0.00989053, 0.00034953, 0.02492997, 0.00034953, 0.00986902,\n",
      "       0.00034953, 0.02072368, 0.00382628, 0.00034953, 0.00034953,\n",
      "       0.00034953, 0.00382628, 0.00789384, 0.00034953, 0.00792626,\n",
      "       0.00382628, 0.00671932, 0.00034953, 0.02157687, 0.00499944,\n",
      "       0.00034953, 0.00034953, 0.00034953, 0.00499944, 0.0073638 ,\n",
      "       0.0004013 , 0.01993263, 0.00499944, 0.0085273 , 0.0004013 ,\n",
      "       0.01330946, 0.01003254, 0.00034953, 0.00034953, 0.00034953,\n",
      "       0.01003254, 0.0074096 , 0.0015392 , 0.01646675, 0.01003254,\n",
      "       0.00912196, 0.0016952 , 0.0131492 , 0.00662631, 0.00034953,\n",
      "       0.00034953, 0.00034953, 0.00662631, 0.00878557, 0.0020921 ,\n",
      "       0.01430601, 0.00662631, 0.00880632, 0.0015557 , 0.01283306,\n",
      "       0.00863953, 0.00034953, 0.00034953, 0.00034953, 0.00863953,\n",
      "       0.00889076, 0.0020921 , 0.01380605, 0.00863953, 0.00916518,\n",
      "       0.00144249, 0.01140293]), 'std_score_time': array([0.00502666, 0.00298901, 0.00314374, 0.0027276 , 0.00470075,\n",
      "       0.00919499, 0.00747153, 0.00990154, 0.00500517, 0.00709982,\n",
      "       0.00778506, 0.00939833, 0.00504964, 0.00293993, 0.00465391,\n",
      "       0.00259845, 0.00469518, 0.00886713, 0.00739684, 0.01009921,\n",
      "       0.0200283 , 0.01768967, 0.02364003, 0.00378453, 0.00472255,\n",
      "       0.00299153, 0.00313365, 0.006279  , 0.01679737, 0.03055945,\n",
      "       0.01956683, 0.00866866, 0.0044973 , 0.00534299, 0.00875643,\n",
      "       0.00528662, 0.00515985, 0.00307618, 0.00349418, 0.00417579,\n",
      "       0.00409497, 0.00602616, 0.00813309, 0.01989797, 0.00414407,\n",
      "       0.00529919, 0.00882818, 0.00626331, 0.00429878, 0.00345278,\n",
      "       0.00417601, 0.00569087, 0.00431459, 0.00657343, 0.00856373,\n",
      "       0.01169156, 0.00414391, 0.00544546, 0.01188023, 0.00676836,\n",
      "       0.00431682, 0.01612604, 0.00537318, 0.02130318, 0.00452694,\n",
      "       0.00512842, 0.00819847, 0.01187729, 0.01411025, 0.00672925,\n",
      "       0.04983638, 0.00656499]), 'split0_test_score': array([0.82444578, 0.82444578, 0.82444578, 0.82444578, 0.82444578,\n",
      "       0.84481726, 0.82444578, 0.7669263 , 0.82444578, 0.83343319,\n",
      "       0.82444578, 0.78669862, 0.84301977, 0.82444578, 0.82444578,\n",
      "       0.82444578, 0.84301977, 0.82983823, 0.82444578, 0.73756741,\n",
      "       0.84301977, 0.82624326, 0.82444578, 0.74595566, 0.85200719,\n",
      "       0.82444578, 0.82444578, 0.82444578, 0.85200719, 0.82504494,\n",
      "       0.82444578, 0.72857999, 0.85200719, 0.82804074, 0.82444578,\n",
      "       0.74775315, 0.85140803, 0.82444578, 0.82444578, 0.82444578,\n",
      "       0.85140803, 0.82684242, 0.82504494, 0.73097663, 0.85140803,\n",
      "       0.82983823, 0.82384661, 0.73816657, 0.85859796, 0.82444578,\n",
      "       0.82444578, 0.82444578, 0.85859796, 0.8286399 , 0.82324745,\n",
      "       0.72798083, 0.85859796, 0.82923907, 0.82444578, 0.73517076,\n",
      "       0.85560216, 0.82444578, 0.82444578, 0.82444578, 0.85560216,\n",
      "       0.8286399 , 0.82324745, 0.72917915, 0.85560216, 0.8286399 ,\n",
      "       0.82444578, 0.7345716 ]), 'split0_train_score': array([0.82483503, 0.82483503, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.97210558, 0.82483503, 0.77054589, 0.82483503, 0.9820036 ,\n",
      "       0.82483503, 0.78569286, 0.85842831, 0.82483503, 0.82483503,\n",
      "       0.82483503, 0.85842831, 0.99430114, 0.82483503, 0.74115177,\n",
      "       0.85842831, 0.99835033, 0.82483503, 0.7529994 , 0.8845231 ,\n",
      "       0.82483503, 0.82483503, 0.82483503, 0.8845231 , 0.99730054,\n",
      "       0.82708458, 0.74145171, 0.8845231 , 0.9985003 , 0.82738452,\n",
      "       0.75089982, 0.90656869, 0.82483503, 0.82483503, 0.82483503,\n",
      "       0.90656869, 0.99835033, 0.98920216, 0.74415117, 0.90656869,\n",
      "       0.99880024, 0.9970006 , 0.74265147, 0.9205159 , 0.82483503,\n",
      "       0.82483503, 0.82483503, 0.9205159 , 0.99865027, 0.99880024,\n",
      "       0.74025195, 0.9205159 , 0.99895021, 0.99880024, 0.73830234,\n",
      "       0.92831434, 0.82483503, 0.82483503, 0.82483503, 0.92831434,\n",
      "       0.99865027, 0.99880024, 0.74190162, 0.92831434, 0.99895021,\n",
      "       0.99895021, 0.73770246]), 'std_train_score': array([8.73685398e-05, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       8.73685398e-05, 1.05838176e-03, 8.73685398e-05, 1.89389751e-02,\n",
      "       8.73685398e-05, 8.76128787e-04, 8.73685398e-05, 2.19771405e-02,\n",
      "       1.87674407e-03, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       1.87674407e-03, 4.49003616e-04, 8.73685398e-05, 4.76383203e-03,\n",
      "       1.87674407e-03, 2.40052112e-04, 8.73685398e-05, 1.56543983e-02,\n",
      "       2.97804730e-03, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       2.97804730e-03, 3.97832943e-04, 6.64932604e-04, 1.00213363e-02,\n",
      "       2.97804730e-03, 1.75013926e-04, 7.72607405e-04, 1.08380084e-02,\n",
      "       1.25995446e-03, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       1.25995446e-03, 2.75010954e-04, 9.02983557e-04, 9.39525537e-03,\n",
      "       1.25995446e-03, 1.47050149e-04, 3.14702191e-04, 7.89143683e-03,\n",
      "       1.92992625e-03, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       1.92992625e-03, 1.74959972e-04, 1.74970721e-04, 1.21973581e-02,\n",
      "       1.92992625e-03, 1.34227751e-04, 2.03506128e-04, 8.15904801e-03,\n",
      "       1.83217895e-03, 8.73685398e-05, 8.73685398e-05, 8.73685398e-05,\n",
      "       1.83217895e-03, 1.80067457e-04, 1.74970721e-04, 1.13863395e-02,\n",
      "       1.83217895e-03, 1.34227751e-04, 1.47000601e-04, 7.35657358e-03])}\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator')\n",
    "print(svc_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(svc_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(svc_clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(svc_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8642197433129423\n",
    "{'C': 2, 'gamma': 'auto', 'kernel': 'linear'} 'C':[0.025, 0.25, 0.5, 1, 2, 3, 5, 8, 10, 15, 20], \n",
    "48\n",
    "<function _passthrough_scorer at 0x2ba712f58950>\n",
    "5\n",
    "9.254388332366943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f2296f2aee4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mknn_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mknn_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# KNN takes dense input in scikit-learn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mopt_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KNeighbors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[0;32m--> 572\u001b[0;31m                                   is_multimetric)\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 delayed_query(\n\u001b[1;32m    454\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/DM/.env/lib/python3.5/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# p: Power parameter for the Minkowski metric. When p = 1, \n",
    "#    this is equivalent to using manhattan_distance (l1), \n",
    "#    and euclidean_distance (l2) for p = 2. \n",
    "#    For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [3, 5, 9, 13, 19, 25, 35, 55, 63], \n",
    "    'leaf_size': [20, 30, 40, 50, 60],\n",
    "    'p': [1, 2, 3]\n",
    "}\n",
    "          \n",
    "knn = KNeighborsClassifier()\n",
    "knn_clf = GridSearchCV(knn, params, cv=5)\n",
    "knn_clf = knn_clf.fit(X.todense(), y) # KNN takes dense input in scikit-learn\n",
    "\n",
    "opt_results['KNeighbors'] = knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator')\n",
    "print(knn_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(knn_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(knn_clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(knn_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layer_sizes': [(10,5), (20,10), (20), (30,20), (50,30)], \n",
    "    'activation': ['tanh', 'relu', 'logistic'], \n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.01, 0.001, 0.1],\n",
    "    'max_iter': [50, 200, 400]\n",
    "}\n",
    "                        \n",
    "mlp = MLPClassifier()\n",
    "mlp_clf = GridSearchCV(mlp, params, cv=5)\n",
    "mlp_clf = mlp_clf.fit(X, y)\n",
    "\n",
    "opt_results['MLP'] = mlp_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Estimator')\n",
    "print(clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(clf.best_score_)\n",
    "print('Best Params')\n",
    "print(clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ... add import for Kmeans"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'n_clusters': [3, 4, 5, 6, 7, 8, 10, 15, 25, 32],\n",
    "    'n_init': [*range(5, 25, 5)],\n",
    "    'max_iter': [*range(200, 450, 100)],\n",
    "    'precompute_distances': ('auto'),\n",
    "    'algorithm' : ('auto', 'full', 'elkan'),\n",
    "}\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans_clf = GridSearchCV(kmeans, params, cv=5)\n",
    "kmeans_clf = kmeans_clf.fit(X)\n",
    "\n",
    "opt_results['KMeans'] = kmeans_clf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Best Estimator')\n",
    "print(kmeans_clf.best_estimator_)\n",
    "print('Best Score')\n",
    "print(kmeans_clf.best_score_)\n",
    "print('Best Params')\n",
    "print(kmeans_clf.best_params_)\n",
    "print('cv_results_')\n",
    "print(kmeans_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All classifiers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "names = ['Nearest Neighbors', 'Linear SVM', 'RBF SVM', 'Gaussian Process',\n",
    "         'Decision Tree', 'Random Forest', 'Neural Net', 'AdaBoost',\n",
    "         'Naive Bayes']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    #SVC(kernel='linear', C=0.025),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    SVC,\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(criterion='gini'),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result_file = open('scikit_learn_results.txt', 'w') \n",
    "for name, classifier in zip(names, classifiers):\n",
    "    print('Running: ', name)\n",
    "    y_true, y_pred = y, cross_val_predict(classifier, X, y, n_jobs=5, cv=3)\n",
    "    result_file.write('\\n\\n--- ' + name + ' ---')\n",
    "    result_file.write('\\nPrecision:' + str(precision_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nRecall:' + str(recall_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nF1-score:' + str(f1_score(y_true, y_pred, average='weighted')))\n",
    "    result_file.write('\\nAccuracy:' + str(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "result_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
